\section{Footstep Evaluation Network}
\label{sec:methodology-footstep-evaluation-network}

The purpose of the footstep evaluation network is to generate
footstep candidates for the GaitNet model. These footstep candidates
allow the remainder of the system to work in a discrete space, only
choosing from a set of these footstep candidates instead of
optimizing over the whole space. Because of this, the precise output
of this network is not critical; rather, it is essential that the
network provides high-quality candidates when sampled. It achieves
this by estimating the cost associated with potential footsteps given
the current robot state. The network's architecture and training
process are largely based on ContactNet
\cite{bratta_contactnet_2024}, with several key modifications
described in the following section.

The primary reason for the differences between this Footstep
Evaluation Network and ContactNet \cite{bratta_contactnet_2024} is
because of their slightly different use cases. ContactNet was
designed to provide a single action at each evaluation, whereas the
Footstep Evaluation Network needs to provide multiple feasible
candidate actions to be narrowed down later. Despite this different
use case, ContactNet still provides much of the guidance for this
implementation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Architecture}
\label{subsec:methodology-contactnet-architecture}

The footstep evaluation network is responsible for generating a set
of footstep candidates $\mathbf{f_c}$ based on footstep evaluation
network input $\mathbf x_c$:

\begin{equation}
  \mathbf{x_c} =
  \begin{bmatrix}
    \mathbf p_{b,xy} \\
    \mathbf r_{w,z} \\
    \mathbf v_b \\
    \mathbf \omega_b \\
    \mathbf u
  \end{bmatrix}
  \label{eq:contactnet-x}
\end{equation}

Here, $\mathbf p_{b,xy}$ represents the $x$ and $y$ positions of all
end effectors in the base frame, stacked into a single vector, and
$\mathbf r_{w,z}$ denotes the height of the robot's center of mass in
the world frame, $\mathbf v_b$ is linear velocity of the robot in the
root frame, $\mathbf \omega_b$ is the angular velocity of the robot
in the root frame, and $\mathbf u$ is the control input as a vector
of $[v_x, v_y, \omega_z]$. The inclusion of $\mathbf \omega_b$
distinguishes this formulation from that in
\cite{bratta_contactnet_2024}. This modification was intended to
improve the model's performance in situations with high rotational velocities.

A set of footstep candidates is referred to as a footstep cost map
(\autoref{fig:data-contactnet-costmap}), which stores the expected
cost of different actions the robot could take with its feet. These
maps are represented as four $5 \times 5$ grids, one for each leg.
This choice differs from the implementation in
\cite{bratta_contactnet_2024}, a larger grid size was selected to provide
more information for each foot, which is important later when
sampling footstep candidates. Ground truth footstep cost maps are
generated as described in
\autoref{subsec:methodology-contactnet-training}, then the network is
trained to replicate the ground truths. After this the network is
able to quickly generate a footstep cost map based on $\mathbf x_c$.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.5\linewidth]{images/data/footstep-cost-map.png}
  \caption{Example footstep cost maps for all four legs. Darker colors
  indicate lower cost (more favorable) footstep positions.}
  \label{fig:data-contactnet-costmap}
\end{figure}

The architecture of the footstep evaluation network is shown in
\autoref{fig:diagram-contactnet-architecture}. It consists of a
feedforward neural network that initially maps the input through two
fully connected layers of 64 nodes each, both with ReLU activations.
The resulting 64-dimensional feature vector is reshaped into an $8
\times 8$ spatial representation and processed by a convolutional
layer with two output channels, a $3 \times 3$ kernel, stride 1, and
padding 1, followed by a ReLU nonlinearity. The output is flattened
and passed through a final fully connected layer before being
reshaped into a $5 \times 5$ grid. This specific architecture differs
from \cite{bratta_contactnet_2024}, where a larger network without
the convolutional layer was used. These modifications were found to
provide better results for the $5 \times 5$ output grid.

To produce the four footstep candidate maps, this network is
replicated four times\textemdash once per leg\textemdash with weights
not shared between legs. This design allows the network to learn
leg-specific behaviors, accommodating potential asymmetries in the
robot's dynamics.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.5\linewidth]{images/diagrams/contact-network-architecture.png}
  \caption{Footstep evaluation neural network architecture.}
  \label{fig:diagram-contactnet-architecture}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Training}
\label{subsec:methodology-contactnet-training}

The footstep evaluation network is trained to predict heuristic
footstep cost maps, as described in \cite{bratta_contactnet_2024}.
Training data is generated using the simulation environment outlined
in \autoref{sec:methodology-simulation-environment}, but with planar
terrain. As in \cite{bratta_contactnet_2024}, planar terrain is
sufficient for data collection because the cost maps are masked based
on terrain after inference (see
\autoref{subsec:methodology-contactnet-post-processing}).

During training, 100 robots are simulated in parallel, divided into
four groups of 25. Each group tests a grid of footstep positions for
one foot at a time; the front-left group is illustrated in
\autoref{fig:figure-training-fl-sweep}. An \textit{iteration} is
considered complete once all robots have either successfully
completed or failed their assigned motions. Importantly, all robots
begin each iteration from the same initial state.
\autoref{fig:figure-contactnet-training-step} shows an example iteration
from start to finish. Note that the rear right leg's position differs
between \autoref{fig:figure-contactnet-training-step-0} and
\autoref{fig:figure-contactnet-training-step-3} because that was the
solution chosen to be explored further.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.5\textwidth]{images/figures/training-fl-sweep.png}
  \caption{Snapshot showing 25 robots testing different footstep
    positions in parallel. For actual data generation, 100 robots are
  run in parallel, testing 25 footstep positions for each foot at a time.}
  \label{fig:figure-training-fl-sweep}
\end{figure}

% === Define layout constants ===
\def\imgwidth{0.22\textwidth}
\def\xgap{2em}          % horizontal gap between images
\def\arrowwidth{1.2em}  % controls arrow length
\def\arrowshift{1.5em} % vertical offset of arrows

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[node distance=\xgap, baseline=(current bounding
    box.center)]

    % === Style for image blocks ===
    \tikzset{
    imgblock/.style={inner sep=0pt, outer sep=0pt, align=center} }

    % === Subfigure nodes ===
    \node[imgblock] (a)
    {\subcaptionbox{Previous best
      state\\\phantom{M}\label{fig:figure-contactnet-training-step-0}}
    {\includegraphics[width=\imgwidth]{images/figures/steps/0.png}}};

    \node[imgblock, right=of a] (b)
    {\subcaptionbox{Beginning of
      swing\\\phantom{M}\label{fig:figure-contactnet-training-step-1}}
    {\includegraphics[width=\imgwidth]{images/figures/steps/1.png}}};

    \node[imgblock, right=of b] (c)
    {\subcaptionbox{End of
      swing\\\phantom{M}\label{fig:figure-contactnet-training-step-2}}
    {\includegraphics[width=\imgwidth]{images/figures/steps/2.png}}};

    \node[imgblock, right=of c] (d)
    {\subcaptionbox{Continue search from a best
      state\label{fig:figure-contactnet-training-step-3}}
    {\includegraphics[width=\imgwidth]{images/figures/steps/3.png}}};

    % === Arrows ===
    \foreach \src/\dst in {a/b, b/c, c/d}{
      \draw[->, thick] ([yshift=\arrowshift]\src.east) --
    ++(\arrowwidth,0) -- ([yshift=\arrowshift]\dst.west); }

  \end{tikzpicture}

  \caption{Sample iteration of the footstep evaluation network data
    generation process. Note that all 100 robots are present in all
    figures, they just occupy the same space. Additionally, each robot
    only ever moves one leg at a time. (a) shows the previous best
    state, which is used as the starting point for the iteration. (b)
    shows the beginning of the swing phase, where the foot is lifted
    off the ground. (c) shows the end of the swing phase, where the
    foot is placed in a new position. (d) shows the next iteration,
  which continues the search from one of the 10 best states found in (c).}
  \label{fig:figure-contactnet-training-step}
\end{figure}

Data collection proceeds by chaining multiple iterations together,
with control inputs periodically re-sampled from $\mathbf u \in
(-0.2, 0.2) \times (-0.2, 0.2) \times (-0.4, 0.4)$, where $\times$
denotes the Cartesian product. After each iteration, the top 10
actions are inserted into a tree structure as edges, with the
resulting state as the leaf node. The tree is explored by randomly
selecting leaves for expansion, and this process continues until a
predefined maximum number of iterations is reached. To ensure data
quality, iterations in which more than 50\% of the robots fall are
discarded, along with their two parent nodes in the tree. This
approach promotes the collection of diverse, yet successful, training
data. Collecting data as described in this section captures the same
information as the data collection plan described in
\cite{bratta_contactnet_2024}, with the addition of a more broad
range of commanded velocities.

\autoref{fig:data-cn-training-distribution} illustrates the
distribution of foot positions in the training dataset. Darker
regions correspond to discrete points on the $5 \times 5$ footstep
grids; a foot occupies a given position if it was moved there in that
iteration. The uniform coverage indicates that the training dataset
effectively captures a wide range of states.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.5\textwidth]{images/data/foot-placement-heatmaps.png}
  \caption{Foot placement heatmaps showing distribution of foot
    positions in the GaitNet training data. Note that the histograms
  are overlaid in some places, obscuring underlying data.}
  \label{fig:data-cn-training-distribution}
\end{figure}

The purpose of this data collection is to assign a cost to each
potential footstep, forming the candidate set $\mathbf{f_c}$. Costs
are computed heuristically based on simulation outcomes, balancing
stability and efficiency. While similar to the approach in
\cite{bratta_contactnet_2024}, the heuristic employed here differs in
several aspects to better suit the output for footstep candidate sampling.
\autoref{fig:data-costmap-composition-elements} shows the individual
factors used to construct the footstep candidate maps, and
\autoref{fig:data-costmap-composition-combined} displays the
resulting combined cost map. These factors are described below,
referencing the subfigures in
\autoref{fig:data-costmap-composition-elements}

The lin\_vel\_z\_l2 factor
(\autoref{fig:data-costmap-composition-lin_vel_z_l2}) penalizes high
vertical velocity of the trunk. The ang\_vel\_xy\_l2 factor
(\autoref{fig:data-costmap-composition-ang_vel_xy_l2}) penalizes high
angular velocity of the trunk in the horizontal axes. The
joint\_torques\_l2 factor
(\autoref{fig:data-costmap-composition-joint_torques_l2}) penalizes
high joint torques, and the joint\_acc\_l2 factor
(\autoref{fig:data-costmap-composition-joint_acc_l2}) penalizes high
joint accelerations. The control\_error factor
(\autoref{fig:data-costmap-composition-control_error}) penalizes
errors between the control input and actual robot motion. The
inscribed\_circle\_radius factor
(\autoref{fig:data-costmap-composition-inscribed_circle_radius})
measures the distance from the center of mass to the nearest edge of
the support polygon, encouraging the robot to maintain its center of
mass in a stable position. The foot\_hip\_distance factor
(\autoref{fig:data-costmap-composition-foot_hip_distance}) measures
the distance between the hip and foot in the $XY$ plane, encouraging
the robot to keep its feet moving in coordination with the body.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.5\textwidth]{images/data/training/contactnet/costmap-composition/combined.png}
  \caption{Combined cost map from factors in
  \autoref{fig:data-costmap-composition-elements} (not normalized).}
  \label{fig:data-costmap-composition-combined}
\end{figure}

% define subfigure layout constants
\def\subfigwidth{0.2\textwidth}

\begin{figure}[H]
  \centering

  %------------------ ROW 1 ------------------
  \begin{minipage}{\textwidth}
    \centering
    \begin{subfigure}[T]{\subfigwidth}
      \centering
      \includegraphics[width=\textwidth]{images/data/training/contactnet/costmap-composition/lin_vel_z_l2.png}
      \caption{\footnotesize Z linear velocity L2 normalized;
      balanced, with 0.017 spread.}
      \label{fig:data-costmap-composition-lin_vel_z_l2}
    \end{subfigure}\hfill
    \begin{subfigure}[T]{\subfigwidth}
      \centering
      \includegraphics[width=\textwidth]{images/data/training/contactnet/costmap-composition/ang_vel_xy_l2.png}
      \caption{\footnotesize XY angular velocity L2 normalized;
      balanced, with 0.051 spread.}
      \label{fig:data-costmap-composition-ang_vel_xy_l2}
    \end{subfigure}\hfill
    \begin{subfigure}[T]{\subfigwidth}
      \centering
      \includegraphics[width=\textwidth]{images/data/training/contactnet/costmap-composition/joint_torques_l2.png}
      \caption{\footnotesize Joint torques L2 normalized; balanced,
      with 0.069 spread.}
      \label{fig:data-costmap-composition-joint_torques_l2}
    \end{subfigure}\hfill
    \begin{subfigure}[T]{\subfigwidth}
      \centering
      \includegraphics[width=\textwidth]{images/data/training/contactnet/costmap-composition/joint_acc_l2.png}
      \caption{\footnotesize Joint accelerations L2 normalized;
      balanced, with 0.086 spread.}
      \label{fig:data-costmap-composition-joint_acc_l2}
    \end{subfigure}
  \end{minipage}

  \vspace{1.5em}

  %------------------ ROW 2 ------------------
  \begin{minipage}{\textwidth}
    \centering
    \begin{subfigure}[T]{\subfigwidth}
      \centering
      \includegraphics[width=\textwidth]{images/data/training/contactnet/costmap-composition/control_error.png}
      \caption{\footnotesize Control error; balanced, with 0.056 spread.}
      \label{fig:data-costmap-composition-control_error}
    \end{subfigure}
    \hspace{0.0667\textwidth}
    \begin{subfigure}[T]{\subfigwidth}
      \centering
      \includegraphics[width=\textwidth]{images/data/training/contactnet/costmap-composition/inscribed_circle_radius.png}
      \caption{\footnotesize Inscribed circle radius; with 0.240 spread.}
      \label{fig:data-costmap-composition-inscribed_circle_radius}
    \end{subfigure}
    \hspace{0.0667\textwidth}
    \begin{subfigure}[T]{\subfigwidth}
      \centering
      \includegraphics[width=\textwidth]{images/data/training/contactnet/costmap-composition/foot_hip_distance.png}
      \caption{\footnotesize Foot-hip distance; with 0.348 spread.}
      \label{fig:data-costmap-composition-foot_hip_distance}
    \end{subfigure}
  \end{minipage}

  %------------------ CAPTION ------------------
  \caption{Factors influencing footstep candidate maps. \textit{balanced}
    indicates that the values for each leg were balanced to have a
    lower spread, mitigating factors that consistently prefer one leg
    over another. The last number in parentheses indicates the total
  range of the data, the most important factor for the combined cost map.}
  \label{fig:data-costmap-composition-elements}

\end{figure}

As in \cite{bratta_contactnet_2024}, the cost maps are normalized to
enhance training performance. The approach here differs in that the
maps are normalized directly to the range $[0, 1]$, rather than
preserving only the relative ordering of costs as in
\cite{bratta_contactnet_2024}. This direct normalization is crucial
for providing the upstream GaitNet model with maximal information.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Post-Processing}
\label{subsec:methodology-contactnet-post-processing}

The primary purpose of the footstep evaluation network is to provide
high-quality footstep candidates to the GaitNet model. We found the
$5\times 5$ grid overly restrictive masking invalid terrain.
Additionally, the $5\times 5$ grid could only provide a very limited
set of footstep candidates. To address both of these issues, we
propose a post-processing pipeline to augment the output of the
footstep evaluation network to provide more diverse footstep
candidates for this application.

The raw cost map output from the footstep evaluation network
(\autoref{fig:diagram-costmap-processing-raw}) is first upsampled
(\autoref{fig:diagram-costmap-processing-upsample}) to increase the
resolution of possible footstep positions and to match the resolution
of the terrain data. Next, noise is added
(\autoref{fig:diagram-costmap-processing-noise}) to encourage
exploration of a more diverse set of footstep positions; without this
noise, all candidates would cluster in close proximity.

\begin{todo}
  Update the number of candidates in text and diagram.
\end{todo}

The cost map is then filtered based on the robot state and terrain
data (\autoref{fig:diagram-costmap-processing-cspace}) to mask out
invalid actions. This includes positions that are too close to
terrain edges and movements that would attempt to reposition a leg
already in the swing phase (as illustrated by the front right leg in
the figure). Additional masking occurs based on the total number of
legs in the swing phase; when two legs are already in swing, all
remaining options are masked out to prevent unstable motions.
Finally, the top eight candidates from each leg are selected
(\autoref{fig:diagram-costmap-processing-topk}) for processing by
GaitNet. If fewer than eight valid candidates exist for a given leg,
no-action candidates are added to maintain consistent tensor dimensions.

% === Define layout constants ===
\def\imgwidth{0.16\textwidth}
\def\xgap{2em}          % horizontal gap between images
\def\arrowwidth{1.2em}  % controls arrow length
\def\arrowshift{0.5em} % vertical offset of arrows

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[node distance=\xgap, baseline=(current bounding
    box.center)]

    % === Style for image blocks ===
    \tikzset{
    imgblock/.style={inner sep=0pt, outer sep=0pt, align=center} }

    % === Subfigure nodes ===
    \node[imgblock] (a)
    {\subcaptionbox{Raw\label{fig:diagram-costmap-processing-raw}}
    {\includegraphics[width=\imgwidth]{images/diagrams/cost-map-processing/1-default.png}}};

    \node[imgblock, right=of a]
    (b)
    {\subcaptionbox{Upsample\label{fig:diagram-costmap-processing-upsample}}
    {\includegraphics[width=\imgwidth]{images/diagrams/cost-map-processing/2-upscale.png}}};

    \node[imgblock, right=of b]
    (c)
    {\subcaptionbox{Noise\label{fig:diagram-costmap-processing-noise}}
    {\includegraphics[width=\imgwidth]{images/diagrams/cost-map-processing/3-noise.png}}};

    \node[imgblock, right=of c]
    (d)
    {\subcaptionbox{C-space\label{fig:diagram-costmap-processing-cspace}}
    {\includegraphics[width=\imgwidth]{images/diagrams/cost-map-processing/4-masked.png}}};

    \node[imgblock, right=of d]
    (e) {\subcaptionbox{TopK
      (green)\label{fig:diagram-costmap-processing-topk}}
    {\includegraphics[width=\imgwidth]{images/diagrams/cost-map-processing/5-selected.png}}};

    % === Arrows ===
    \foreach \src/\dst in {a/b, b/c, c/d, d/e}{
      \draw[->, thick] ([yshift=\arrowshift]\src.east) --
    ++(\arrowwidth,0) -- ([yshift=\arrowshift]\dst.west); }

  \end{tikzpicture}

  \caption{Cost map processing pipeline. Shows how the raw cost map
  is processed to produce the final footstep candidates.}
  \label{fig:diagram-costmap-processing}
\end{figure}
