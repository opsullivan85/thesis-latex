\section{Simulation Environment}
\label{sec:methodology-simulation-environment}

\begin{outline}
  Describe the physics-based simulation environment (IsaacLab) and
  the quadruped model used for development and testing.
\end{outline}

The simulation environment used for this project is NVIDIA Isaac Lab
\cite{mittal_orbit_2023}. This framework was selected for several
reasons. It is a modern platform with a Python interface designed
specifically for reinforcement learning applications and GPU
parallelism. The use of GPU parallelism enables significantly faster
simulation and data collection, albeit at the cost of increased
programming complexity and reduced compatibility with older hardware.
Furthermore, the extensive collection of example and community
projects provides valuable references for implementing the simulation
features required in this work.

Although both simulation and learning processes are executed on the
GPU, the robot controllers operate on the CPU.
\autoref{fig:diagram-processing-flow} illustrates the overall
processing flow. The simulation environment runs entirely on the GPU,
where multiple robots are simulated in parallel. Meanwhile, the robot
model predictive controllers (MPCs) execute on the CPU, with each
controller running concurrently. The CPU and GPU communicate at every
simulation step to exchange robot states and corresponding control actions.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.5\linewidth]{images/diagrams/processing-flow.png}
  \caption{Block diagram showing the programming tasks computed on
    the CPU versus the GPU. The full simulation is run in parallel
    using NVIDIA Isaac Lab on the GPU, while the robot MPCs are run in
  parallel on the CPU.}
  \label{fig:diagram-processing-flow}
\end{figure}

NVIDIA Isaac Lab uses a declarative system of Python dataclasses to
define the simulation environment. For this work, a custom
environment is used (\autoref{fig:figure-envirnment-close}), including:

\begin{itemize}
  \item Unitree Go 1\textemdash Configured to use force control for each joint.
  \item Terrain raycasts\textemdash Measure the height of the terrain
    at each possible footstep location. This emulates the lidar
    processing steps of a full vision pipeline.
  \item Custom terrain\textemdash A grid of 12$\times$12 sub-terrains
    (4$\times$4\,m each) with increasing difficulty
    (\autoref{fig:figure-envirnment-far}). Each sub-terrain consists
    of a 12\,cm square grid pattern with missing sections. The void
    density varies from approximately 0\% to 40\%. The quantity of
    terrain is limited by GPU memory.
\end{itemize}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.75\linewidth]{images/figures/environment-close.png}
  \caption{Image of a Unitree Go 1 navigating the terrain. Red
    region shows area converted into heightmap for front left leg.
    Black regions show voids in the terrain. Green arrow shows desired
  velocity vector.}
  \label{fig:figure-envirnment-close}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.75\linewidth]{images/figures/environment-far.png}
  \caption{Image showing the full terrain used in simulation.
    Full terrain is a grid of 12$\times$12 sub-terrains with increasing
  difficulty. Sub-terrains are 4$\times$4\,m grids with missing sections.}
  \label{fig:figure-envirnment-far}
\end{figure}
