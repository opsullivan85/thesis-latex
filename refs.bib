
@article{kalakrishnan_learning_2011,
  title        = {Learning, planning, and control for quadruped locomotion over challenging                 terrain},
  volume       = {30},
  rights       = {https://journals.sagepub.com/page/policies/text-and-data-mining-license},
  issn         = {0278-3649, 1741-3176},
  url          = {https://journals.sagepub.com/doi/10.1177/0278364910388677},
  doi          = {10.1177/0278364910388677},
  abstract     = {We present a control architecture for fast quadruped locomotion over rough terrain. We approach the problem by decomposing it into many sub-systems, in which we apply state-of-the-art learning, planning, optimization, and control techniques to achieve robust, fast locomotion. Unique features of our control strategy include: (1) a system that learns optimal foothold choices from expert demonstration using terrain templates, (2) a body trajectory optimizer based on the {ZeroMoment} Point ({ZMP}) stability criterion, and (3) a ﬂoating-base inverse dynamics controller that, in conjunction with force control, allows for robust, compliant locomotion over unperceived obstacles. We evaluate the performance of our controller by testing it on the {LittleDog} quadruped robot, over a wide variety of rough terrains of varying difﬁculty levels. The terrain that the robot was tested on includes rocks, logs, steps, barriers, and gaps, with obstacle sizes up to the leg length of the robot. We demonstrate the generalization ability of this controller by presenting results from testing performed by an independent external test team on terrain that has never been shown to us.},
  pages        = {236--258},
  number       = {2},
  journaltitle = {The International Journal of Robotics Research},
  author       = {Kalakrishnan, Mrinal and Buchli, Jonas and Pastor, Peter and Mistry, Michael and Schaal, Stefan},
  urldate      = {2025-07-14},
  date         = {2011-02},
  langid       = {english},
  note         = {Publisher: {SAGE} Publications},
  file         = {2011 - Learning, planning, and control for quadruped locomotion over challenging terrain.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2011 - Learning, planning, and control for quadruped locomotion over challenging terrain.pdf:application/pdf}
}

@article{zucker_optimization_2011,
  title        = {Optimization and learning for rough terrain legged locomotion},
  volume       = {30},
  rights       = {https://journals.sagepub.com/page/policies/text-and-data-mining-license},
  issn         = {0278-3649, 1741-3176},
  url          = {https://journals.sagepub.com/doi/10.1177/0278364910392608},
  doi          = {10.1177/0278364910392608},
  abstract     = {We present a novel approach to legged locomotion over rough terrain that is thoroughly rooted in optimization. This approach relies on a hierarchy of fast, anytime algorithms to plan a set of footholds, along with the dynamic body motions required to execute them. Components within the planning framework coordinate to exchange plans, cost-to-go estimates, and “certiﬁcates” that ensure the output of an abstract high-level planner can be realized by lower layers of the hierarchy. The burden of careful engineering of cost functions to achieve desired performance is substantially mitigated by a simple inverse optimal control technique. Robustness is achieved by real-time re-planning of the full trajectory, augmented by reﬂexes and feedback control. We demonstrate the successful application of our approach in guiding the {LittleDog} quadruped robot over a variety of rough terrains. Other novel aspects of our past research eﬀorts include a variety of pioneering inverse optimal control techniques as well as a system for planning using arbitrary pre-recorded robot behaviors.},
  pages        = {175--191},
  number       = {2},
  journaltitle = {The International Journal of Robotics Research},
  author       = {Zucker, Matt and Ratliff, Nathan and Stolle, Martin and Chestnutt, Joel and Bagnell, J Andrew and Atkeson, Christopher G and Kuffner, James},
  urldate      = {2025-07-14},
  date         = {2011-02},
  langid       = {english},
  note         = {Publisher: {SAGE} Publications},
  file         = {2011 - Optimization and Learning for Rough-Terrain Legged Locomotion.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2011 - Optimization and Learning for Rough-Terrain Legged Locomotion.pdf:application/pdf}
}

@inproceedings{todorov_mujoco_2012,
  location   = {Vilamoura-Algarve, Portugal},
  title      = {{MuJoCo}: A physics engine for model-based control},
  url        = {http://ieeexplore.ieee.org/document/6386109/},
  doi        = {10.1109/iros.2012.6386109},
  shorttitle = {{MuJoCo}},
  abstract   = {We describe a new physics engine tailored to model-based control. Multi-joint dynamics are represented in generalized coordinates and computed via recursive algorithms. Contact responses are computed via efﬁcient new algorithms we have developed, based on the modern velocity-stepping approach which avoids the difﬁculties with spring-dampers. Models are speciﬁed using either a high-level C++ {API} or an intuitive {XML} ﬁle format. A built-in compiler transforms the user model into an optimized data structure used for runtime computation. The engine can compute both forward and inverse dynamics. The latter are well-deﬁned even in the presence of contacts and equality constraints. The model can include tendon wrapping as well as actuator activation states (e.g. pneumatic cylinders or muscles). To facilitate optimal control applications and in particular sampling and ﬁnite differencing, the dynamics can be evaluated for different states and controls in parallel. Around 400,000 dynamics evaluations per second are possible on a 12-core machine, for a 3D homanoid with 18 dofs and 6 active contacts. We have already used the engine in a number of control applications. It will soon be made publicly available.},
  eventtitle = {2012 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS} 2012)},
  booktitle  = {2012 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
  publisher  = {{IEEE}},
  author     = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  urldate    = {2025-07-14},
  date       = {2012-10},
  langid     = {english},
  file       = {2012 - MuJoCo A physics engine for model-based control.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2012 - MuJoCo A physics engine for model-based control.pdf:application/pdf}
}

@article{peng_deeploco_2017,
  title        = {{DeepLoco}: dynamic locomotion skills using hierarchical deep reinforcement learning},
  volume       = {36},
  rights       = {https://www.acm.org/publications/policies/copyright\_policy\#Background},
  issn         = {0730-0301, 1557-7368},
  url          = {https://dl.acm.org/doi/10.1145/3072959.3073602},
  doi          = {10.1145/3072959.3073602},
  shorttitle   = {{DeepLoco}},
  abstract     = {Learning physics-based locomotion skills is a difficult problem, leading to solutions that typically exploit prior knowledge of various forms. In this paper we aim to learn a variety of environment-aware locomotion skills with a limited amount of prior knowledge. We adopt a two-level hierarchical control framework. First, low-level controllers are learned that operate at a fine timescale and which achieve robust walking gaits that satisfy stepping-target and style objectives. Second, high-level controllers are then learned which plan at the timescale of steps by invoking desired step targets for the low-level controller. The high-level controller makes decisions directly based on high-dimensional inputs, including terrain maps or other suitable representations of the surroundings. Both levels of the control policy are trained using deep reinforcement learning. Results are demonstrated on a simulated 3D biped. Low-level controllers are learned for a variety of motion styles and demonstrate robustness with respect to force-based disturbances, terrain variations, and style interpolation. High-level controllers are demonstrated that are capable of following trails through terrains, dribbling a soccer ball towards a target location, and navigating through static or dynamic obstacles.},
  pages        = {1--13},
  number       = {4},
  journaltitle = {{ACM} Transactions on Graphics},
  shortjournal = {{ACM} Trans. Graph.},
  author       = {Peng, Xue Bin and Berseth, Glen and Yin, Kangkang and Van De Panne, Michiel},
  urldate      = {2025-07-14},
  date         = {2017-08-31},
  langid       = {english},
  note         = {Publisher: Association for Computing Machinery ({ACM})},
  file         = {2017 - DeepLoco Dynamic Locomotion Skills Using Hierarchical Deep Reinforcement Learning.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2017 - DeepLoco Dynamic Locomotion Skills Using Hierarchical Deep Reinforcement Learning.pdf:application/pdf}
}

@article{winkler_gait_2018,
  title        = {Gait and Trajectory Optimization for Legged Systems Through Phase-Based End-Effector Parameterization},
  volume       = {3},
  rights       = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
  issn         = {2377-3766, 2377-3774},
  url          = {http://ieeexplore.ieee.org/document/8283570/},
  doi          = {10.1109/lra.2018.2798285},
  abstract     = {We present a single Trajectory Optimization formulation for legged locomotion that automatically determines the gait-sequence, step-timings, footholds, swing-leg motions and 6D body motion over non-ﬂat terrain, without any additional modules. Our phase-based parameterization of feet motion and forces allows to optimize over the discrete gait sequence using only continuous decision variables. The system is represented using a simpliﬁed Centroidal dynamics model that is inﬂuenced by the feet’s location and forces. We explicitly enforce friction cone constraints, depending on the shape of the terrain. The {NLP} solver generates highly dynamic motion-plans with full ﬂight-phases for a variety of legged systems with arbitrary morphologies in an efﬁcient manner. We validate the feasibility of the generated plans in simulation and on the real quadruped robot {ANYmal}. Additionally, the entire solver software {TOWR} used to generate these motions is made freely available.},
  pages        = {1560--1567},
  number       = {3},
  journaltitle = {{IEEE} Robotics and Automation Letters},
  shortjournal = {{IEEE} Robot. Autom. Lett.},
  author       = {Winkler, Alexander W. and Bellicoso, C. Dario and Hutter, Marco and Buchli, Jonas},
  urldate      = {2025-07-14},
  date         = {2018-07},
  langid       = {english},
  note         = {Publisher: Institute of Electrical and Electronics Engineers ({IEEE})},
  file         = {2018 - Gait and Trajectory Optimization for Legged Systems through Phase-based End-Effector Parameterization.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2018 - Gait and Trajectory Optimization for Legged Systems through Phase-based End-Effector Parameterization.pdf:application/pdf}
}

@article{villarreal_fast_2019,
  title        = {Fast and Continuous Foothold Adaptation for Dynamic Locomotion through {CNNs}},
  volume       = {4},
  issn         = {2377-3766, 2377-3774},
  url          = {http://arxiv.org/abs/1809.09759},
  doi          = {10.1109/LRA.2019.2899434},
  abstract     = {Legged robots can outperform wheeled machines for most navigation tasks across unknown and rough terrains. For such tasks, visual feedback is a fundamental asset to provide robots with terrain-awareness. However, robust dynamic locomotion on difﬁcult terrains with real-time performance guarantees remains a challenge. We present here a real-time, dynamic foothold adaptation strategy based on visual feedback. Our method adjusts the landing position of the feet in a fully reactive manner, using only on-board computers and sensors. The correction is computed and executed continuously along the swing phase trajectory of each leg. To efﬁciently adapt the landing position, we implement a self-supervised foothold classiﬁer based on a Convolutional Neural Network ({CNN}). Our method results in an up to 200 times faster computation with respect to the full-blown heuristics. Our goal is to react to visual stimuli from the environment, bridging the gap between blind reactive locomotion and purely vision-based planning strategies. We assess the performance of our method on the dynamic quadruped robot {HyQ}, executing static and dynamic gaits (at speeds up to 0.5 m/s) in both simulated and real scenarios; the beneﬁt of safe foothold adaptation is clearly demonstrated by the overall robot behavior.},
  pages        = {2140--2147},
  number       = {2},
  journaltitle = {{IEEE} Robotics and Automation Letters},
  shortjournal = {{IEEE} Robot. Autom. Lett.},
  author       = {Villarreal, Octavio and Barasuol, Victor and Camurri, Marco and Franceschi, Luca and Focchi, Michele and Pontil, Massimiliano and Caldwell, Darwin G. and Semini, Claudio},
  urldate      = {2025-07-14},
  date         = {2019-04},
  langid       = {english},
  eprinttype   = {arxiv},
  eprint       = {1809.09759 [cs]},
  keywords     = {Computer Science - Robotics},
  file         = {2019 - Fast and Continuous Foothold Adaptation for Dynamic Locomotion through CNNs.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2019 - Fast and Continuous Foothold Adaptation for Dynamic Locomotion through CNNs.pdf:application/pdf}
}

@misc{tsounis_deepgait_2020,
  title      = {{DeepGait}: Planning and Control of Quadrupedal Gaits using Deep Reinforcement Learning},
  url        = {http://arxiv.org/abs/1909.08399},
  doi        = {10.48550/arXiv.1909.08399},
  shorttitle = {{DeepGait}},
  abstract   = {This paper addresses the problem of legged locomotion in non-ﬂat terrain. As legged robots such as quadrupeds are to be deployed in terrains with geometries which are difﬁcult to model and predict, the need arises to equip them with the capability to generalize well to unforeseen situations. In this work, we propose a novel technique for training neuralnetwork policies for terrain-aware locomotion, which combines state-of-the-art methods for model-based motion planning and reinforcement learning. Our approach is centered on formulating Markov decision processes using the evaluation of dynamic feasibility criteria in place of physical simulation. We thus employ policy-gradient methods to independently train policies which respectively plan and execute foothold and base motions in 3D environments using both proprioceptive and exteroceptive measurements. We apply our method within a challenging suite of simulated terrain scenarios which contain features such as narrow bridges, gaps and stepping-stones, and train policies which succeed in locomoting effectively in all cases.},
  number     = {{arXiv}:1909.08399},
  publisher  = {{arXiv}},
  author     = {Tsounis, Vassilios and Alge, Mitja and Lee, Joonho and Farshidian, Farbod and Hutter, Marco},
  urldate    = {2025-07-14},
  date       = {2020-01-31},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {1909.08399 [cs]},
  keywords   = {Computer Science - Machine Learning, Computer Science - Robotics},
  file       = {2020 - DeepGait Planning and Control of Quadrupedal Gaits using Deep Reinforcement Learning.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2020 - DeepGait Planning and Control of Quadrupedal Gaits using Deep Reinforcement Learning.pdf:application/pdf}
}

@misc{meduri_deepq_2020,
  title      = {{DeepQ} Stepper: A framework for reactive dynamic walking on uneven terrain},
  url        = {http://arxiv.org/abs/2010.14834},
  doi        = {10.48550/arXiv.2010.14834},
  shorttitle = {{DeepQ} Stepper},
  abstract   = {Reactive stepping and push recovery for biped robots is often restricted to ﬂat terrains because of the difﬁculty in computing capture regions for nonlinear dynamic models. In this paper, we address this limitation by using reinforcement learning to approximately learn the 3D capture region for such systems. We propose a novel 3D reactive stepper, The {DeepQ} stepper, that computes optimal step locations for walking at different velocities using the 3D capture regions approximated by the action-value function. We demonstrate the ability of the approach to learn stepping with a simpliﬁed 3D pendulum model and a full robot dynamics. Further, the stepper achieves a higher performance when it learns approximate capture regions while taking into account the entire dynamics of the robot that are often ignored in existing reactive steppers based on simpliﬁed models. The {DeepQ} stepper can handle non convex terrain with obstacles, walk on restricted surfaces like stepping stones and recover from external disturbances for a constant computational cost.},
  number     = {{arXiv}:2010.14834},
  publisher  = {{arXiv}},
  author     = {Meduri, Avadesh and Khadiv, Majid and Righetti, Ludovic},
  urldate    = {2025-07-14},
  date       = {2020-10-28},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2010.14834 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2020 - DeepQ Stepper A framework for reactive dynamic walking on uneven terrain.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2020 - DeepQ Stepper A framework for reactive dynamic walking on uneven terrain.pdf:application/pdf}
}

@article{lee_learning_2020,
  title        = {Learning Quadrupedal Locomotion over Challenging Terrain},
  volume       = {5},
  issn         = {2470-9476},
  url          = {http://arxiv.org/abs/2010.11251},
  doi          = {10.1126/scirobotics.abc5986},
  abstract     = {Some of the most challenging environments on our planet are accessible to quadrupedal animals but remain out of reach for autonomous machines. Legged locomotion can dramatically expand the operational domains of robotics. However, conventional controllers for legged locomotion are based on elaborate state machines that explicitly trigger the execution of motion primitives and reflexes. These designs have escalated in complexity while falling short of the generality and robustness of animal locomotion. Here we present a radically robust controller for legged locomotion in challenging natural environments. We present a novel solution to incorporating proprioceptive feedback in locomotion control and demonstrate remarkable zero-shot generalization from simulation to natural environments. The controller is trained by reinforcement learning in simulation. It is based on a neural network that acts on a stream of proprioceptive signals. The trained controller has taken two generations of quadrupedal {ANYmal} robots to a variety of natural environments that are beyond the reach of prior published work in legged locomotion. The controller retains its robustness under conditions that have never been encountered during training: deformable terrain such as mud and snow, dynamic footholds such as rubble, and overground impediments such as thick vegetation and gushing water. The presented work opens new frontiers for robotics and indicates that radical robustness in natural environments can be achieved by training in much simpler domains.},
  number       = {47},
  journaltitle = {Science Robotics},
  shortjournal = {Sci. Robot.},
  author       = {Lee, Joonho and Hwangbo, Jemin and Wellhausen, Lorenz and Koltun, Vladlen and Hutter, Marco},
  urldate      = {2025-07-14},
  date         = {2020-10-21},
  langid       = {english},
  eprinttype   = {arxiv},
  eprint       = {2010.11251 [cs]},
  keywords     = {Computer Science - Machine Learning, Computer Science - Robotics, Computer Science - Systems and Control, Electrical Engineering and Systems Science - Systems and Control},
  file         = {2020 - Learning Quadrupedal Locomotion over Challenging T.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2020 - Learning Quadrupedal Locomotion over Challenging T.pdf:application/pdf}
}

@inproceedings{zhu_off-road_2020,
  title      = {Off-road Autonomous Vehicles Traversability Analysis and Trajectory Planning Based on Deep Inverse Reinforcement Learning},
  url        = {http://arxiv.org/abs/1909.06953},
  doi        = {10.1109/IV47402.2020.9304721},
  abstract   = {Terrain traversability analysis is a fundamental issue to achieve the autonomy of a robot at off-road environments. Geometry-based and appearance-based methods have been studied in decades, while behavior-based methods exploiting learning from demonstration ({LfD}) are new trends. Behaviorbased methods learn cost functions that guide trajectory planning in compliance with experts’ demonstrations, which can be more scalable to various scenes and driving behaviors. This research proposes a method of off-road traversability analysis and trajectory planning using Deep Maximum Entropy Inverse Reinforcement Learning. To incorporate the vehicle’s kinematics while solving the problem of exponential increase of state-space complexity, two convolutional neural networks, i.e., {RL} {ConvNet} and Svf {ConvNet}, are developed to encode kinematics into convolution kernels and achieve efﬁcient forward reinforcement learning. We conduct experiments in off-road environments. Scene maps are generated using 3D {LiDAR} data, and expert demonstrations are either the vehicle’s real driving trajectories at the scene or synthesized ones to represent speciﬁc behaviors such as crossing negative obstacles. Different cost functions of traversability analysis are learned and tested at various scenes of capability in guiding the trajectory planning of different behaviors. We also demonstrate the peformance and computation efﬁciency of the proposed method.},
  pages      = {971--977},
  author     = {Zhu, Zeyu and Li, Nan and Sun, Ruoyu and Zhao, Huijing and Xu, Donghao},
  urldate    = {2025-07-14},
  date       = {2020-10-19},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {1909.06953 [cs]},
  keywords   = {Computer Science - Machine Learning, Computer Science - Robotics},
  file       = {2020 - Off-road Autonomous Vehicles Traversability Analys.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2020 - Off-road Autonomous Vehicles Traversability Analys.pdf:application/pdf}
}

@article{hong_real-time_2020,
  title        = {Real-Time Feasible Footstep Planning for Bipedal Robots in Three-Dimensional Environments Using Particle Swarm Optimization},
  volume       = {25},
  rights       = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
  issn         = {1083-4435, 1941-014X},
  url          = {https://ieeexplore.ieee.org/document/8911501/},
  doi          = {10.1109/tmech.2019.2955701},
  abstract     = {Footstep planning in various threedimensional environments is formulated as an optimization problem, which is solved using a particle swarm optimization. The objective function for optimization is designed to achieve real-time footstep planning considering arrival at the goal with effective not only foot placements but also walking periods, kinematic constraints: obstacle avoidance and hardware limitations, and dynamic constraints for the bipedal dynamics: stability while walking and feasibility of footsteps in a walking pattern generator. Speciﬁcally, optimization objectives are to minimize remaining distance to the goal, lateral movement, rotational movement, and walking period variation. Three penalties are also considered depending on the situations. The ﬁrst penalty is for obstacle collision avoidance along with prevention of unstable walking due to excessive footstep height variation. The second penalty is for walking satisfying stable zero-moment point condition along with the foot collision avoidance. The third penalty is for feasible footstep planning in a walking pattern generator. Any approximation or precomputation is not required for the proposed footstep planning method. The validity of the proposed method is veriﬁed through experiments in various 3-D environments with static and dynamic obstacles.},
  pages        = {429--437},
  number       = {1},
  journaltitle = {{IEEE}/{ASME} Transactions on Mechatronics},
  shortjournal = {{IEEE}/{ASME} Trans. Mechatron.},
  author       = {Hong, Young-Dae and Lee, Bumjoo},
  urldate      = {2025-07-14},
  date         = {2020-02},
  langid       = {english},
  note         = {Publisher: Institute of Electrical and Electronics Engineers ({IEEE})},
  file         = {2020 - Real-Time Feasible Footstep Planning for Bipedal Robots in Three-Dimensional Environments Using Particle Swarm Optimization.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2020 - Real-Time Feasible Footstep Planning for Bipedal Robots in Three-Dimensional Environments Using Particle Swarm Optimization.pdf:application/pdf}
}

@misc{siekmann_blind_2021,
  title      = {Blind Bipedal Stair Traversal via Sim-to-Real Reinforcement Learning},
  url        = {http://arxiv.org/abs/2105.08328},
  doi        = {10.48550/arXiv.2105.08328},
  abstract   = {Accurate and precise terrain estimation is a difﬁcult problem for robot locomotion in real-world environments. Thus, it is useful to have systems that do not depend on accurate estimation to the point of fragility. In this paper, we explore the limits of such an approach by investigating the problem of traversing stair-like terrain without any external perception or terrain models on a bipedal robot. For such blind bipedal platforms, the problem appears difﬁcult (even for humans) due to the surprise elevation changes. Our main contribution is to show that sim-to-real reinforcement learning ({RL}) can achieve robust locomotion over stair-like terrain on the bipedal robot Cassie using only proprioceptive feedback. Importantly, this only requires modifying an existing ﬂat-terrain training {RL} framework to include stair-like terrain randomization, without any changes in reward function. To our knowledge, this is the ﬁrst controller for a bipedal, human-scale robot capable of reliably traversing a variety of real-world stairs and other stair-like disturbances using only proprioception.},
  number     = {{arXiv}:2105.08328},
  publisher  = {{arXiv}},
  author     = {Siekmann, Jonah and Green, Kevin and Warila, John and Fern, Alan and Hurst, Jonathan},
  urldate    = {2025-07-14},
  date       = {2021-05-18},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2105.08328 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2021 - Blind Bipedal Stair Traversal via Sim-to-Real Rein.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2021 - Blind Bipedal Stair Traversal via Sim-to-Real Rein.pdf:application/pdf}
}

@inbook{xie_glide_2023,
  location   = {Cham},
  title      = {{GLiDE}: Generalizable Quadrupedal Locomotion in Diverse Environments with a Centroidal Model},
  rights     = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn       = {978-3-031-21089-1 978-3-031-21090-7},
  url        = {https://link.springer.com/10.1007/978-3-031-21090-7_31},
  shorttitle = {{GLiDE}},
  abstract   = {Model-free reinforcement learning ({RL}) for legged locomotion commonly relies on a physics simulator that can accurately predict the behaviors of every degree of freedom of the robot. In contrast, approximate reduced-order models are often sufﬁcient for many model-based control strategies. In this work we explore how {RL} can be effectively used with a centroidal model to generate robust control policies for quadrupedal locomotion. Advantages over {RL} with a full-order model include a simple reward structure, reduced computational costs, and robust sim-to-real transfer. We further show the potential of the method by demonstrating stepping-stone locomotion, twolegged in-place balance, balance beam locomotion, and sim-toreal transfer without further adaptations. Additional Results: https://www.pair.toronto.edu/glide-quadruped/.},
  pages      = {523--539},
  booktitle  = {Springer Proceedings in Advanced Robotics},
  publisher  = {Springer International Publishing},
  bookauthor = {Xie, Zhaoming and Da, Xingye and Babich, Buck and Garg, Animesh and De Panne, Michiel Van},
  urldate    = {2025-07-14},
  date       = {2023},
  langid     = {english},
  doi        = {10.1007/978-3-031-21090-7_31},
  note       = {{ISSN}: 2511-1256, 2511-1264},
  file       = {2021 - GLiDE Generalizable Quadrupedal Locomotion in Diverse Environments with a Centroidal Model.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2021 - GLiDE Generalizable Quadrupedal Locomotion in Diverse Environments with a Centroidal Model.pdf:application/pdf}
}

@article{rudin_learning_nodate,
  title    = {Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement Learning},
  abstract = {In this work, we present and study a training set-up that achieves fast policy generation for real-world robotic tasks by using massive parallelism on a single workstation {GPU}. We analyze and discuss the impact of different training algorithm components in the massively parallel regime on the ﬁnal policy performance and training times. In addition, we present a novel game-inspired curriculum that is well suited for training with thousands of simulated robots in parallel. We evaluate the approach by training the quadrupedal robot {ANYmal} to walk on challenging terrain. The parallel approach allows training policies for ﬂat terrain in under four minutes, and in twenty minutes for uneven terrain. This represents a speedup of multiple orders of magnitude compared to previous work. Finally, we transfer the policies to the real robot to validate the approach. We open-source our training code to help accelerate further research in the ﬁeld of learned legged locomotion: https://leggedrobotics.github.io/legged\_gym/.},
  author   = {Rudin, Nikita and Hoeller, David and Hutter, Marco and Reist, Philipp},
  langid   = {english},
  file     = {2021 - Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement Learning.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2021 - Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement Learning.pdf:application/pdf}
}

@inproceedings{wellhausen_rough_2021,
  location   = {Prague, Czech Republic},
  title      = {Rough Terrain Navigation for Legged Robots using Reachability Planning and Template Learning},
  rights     = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
  url        = {https://ieeexplore.ieee.org/document/9636358/},
  doi        = {10.1109/iros51168.2021.9636358},
  abstract   = {Navigation planning for legged robots has distinct challenges compared to wheeled and tracked systems due to the ability to lift legs off the ground and step over obstacles. While most navigation planners assume a ﬁxed traversability value for a single terrain patch, we overcome this limitation by proposing a reachability-based navigation planner for legged robots. We approximate the robot morphology by a set of reachability and body volumes, assuming that the reachability volumes need to always be in contact with the environment, while the body should be contact-free. We train a convolutional neural network to predict foothold scores which are used to restrict geometries which are considered suitable to step on. Using this representation, we propose a navigation planner based on probabilistic roadmaps. Through validation of only low-cost graph edges during graph expansion and an adaptive sampling scheme based on roadmap node density, we achieve real-time performance with fast update rates even in cluttered and narrow environments. We thoroughly validate the proposed navigation planner in simulation and demonstrate its performance in real-world experiments on the quadruped {ANYmal}.},
  eventtitle = {2021 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS})},
  pages      = {6914--6921},
  booktitle  = {2021 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS})},
  publisher  = {{IEEE}},
  author     = {Wellhausen, Lorenz and Hutter, Marco},
  urldate    = {2025-07-14},
  date       = {2021-09-27},
  langid     = {english},
  file       = {2021 - Rough Terrain Navigation for Legged Robots using R.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2021 - Rough Terrain Navigation for Legged Robots using R.pdf:application/pdf}
}

@misc{siekmann_sim--real_2021,
  title      = {Sim-to-Real Learning of All Common Bipedal Gaits via Periodic Reward Composition},
  url        = {http://arxiv.org/abs/2011.01387},
  doi        = {10.48550/arXiv.2011.01387},
  abstract   = {We study the problem of realizing the full spectrum of bipedal locomotion on a real robot with sim-to-real reinforcement learning ({RL}). A key challenge of learning legged locomotion is describing different gaits, via reward functions, in a way that is intuitive for the designer and speciﬁc enough to reliably learn the gait across different initial random seeds or hyperparameters. A common approach is to use reference motions (e.g. trajectories of joint positions) to guide learning. However, ﬁnding high-quality reference motions can be difﬁcult and the trajectories themselves narrowly constrain the space of learned motion. At the other extreme, reference-free reward functions are often underspeciﬁed (e.g. move forward) leading to massive variance in policy behavior, or are the product of signiﬁcant reward-shaping via trial-and-error, making them exclusive to speciﬁc gaits. In this work, we propose a rewardspeciﬁcation framework based on composing simple probabilistic periodic costs on basic forces and velocities. We instantiate this framework to deﬁne a parametric reward function with intuitive settings for all common bipedal gaits - standing, walking, hopping, running, and skipping. Using this function we demonstrate successful sim-to-real transfer of the learned gaits to the bipedal robot Cassie, as well as a generic policy that can transition between all of the two-beat gaits.},
  number     = {{arXiv}:2011.01387},
  publisher  = {{arXiv}},
  author     = {Siekmann, Jonah and Godse, Yesh and Fern, Alan and Hurst, Jonathan},
  urldate    = {2025-07-14},
  date       = {2021-03-11},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2011.01387 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2021 - Sim-to-Real Learning of All Common Bipedal Gaits via Periodic Reward Composition.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2021 - Sim-to-Real Learning of All Common Bipedal Gaits via Periodic Reward Composition.pdf:application/pdf}
}

@misc{grandia_perceptive_2022,
  title      = {Perceptive Locomotion through Nonlinear Model Predictive Control},
  url        = {http://arxiv.org/abs/2208.08373},
  doi        = {10.48550/arXiv.2208.08373},
  abstract   = {Dynamic locomotion in rough terrain requires accurate foot placement, collision avoidance, and planning of the underactuated dynamics of the system. Reliably optimizing for such motions and interactions in the presence of imperfect and often incomplete perceptive information is challenging. We present a complete perception, planning, and control pipeline, that can optimize motions for all degrees of freedom of the robot in real-time. To mitigate the numerical challenges posed by the terrain a sequence of convex inequality constraints is extracted as local approximations of foothold feasibility and embedded into an online model predictive controller. Steppability classiﬁcation, plane segmentation, and a signed distance ﬁeld are precomputed per elevation map to minimize the computational effort during the optimization. A combination of multipleshooting, real-time iteration, and a ﬁlter-based line-search are used to solve the formulated problem reliably and at high rate. We validate the proposed method in scenarios with gaps, slopes, and stepping stones in simulation and experimentally on the {ANYmal} quadruped platform, resulting in state-of-the-art dynamic climbing.},
  number     = {{arXiv}:2208.08373},
  publisher  = {{arXiv}},
  author     = {Grandia, Ruben and Jenelten, Fabian and Yang, Shaohui and Farshidian, Farbod and Hutter, Marco},
  urldate    = {2025-07-14},
  date       = {2022-08-17},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2208.08373 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2022 - Perceptive Locomotion through Nonlinear Model Predictive Control.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2022 - Perceptive Locomotion through Nonlinear Model Predictive Control.pdf:application/pdf}
}

@article{gangapurwala_rloc_2022,
  title        = {{RLOC}: Terrain-Aware Legged Locomotion using Reinforcement Learning and Optimal Control},
  volume       = {38},
  issn         = {1552-3098, 1941-0468},
  url          = {http://arxiv.org/abs/2012.03094},
  doi          = {10.1109/TRO.2022.3172469},
  shorttitle   = {{RLOC}},
  abstract     = {We present a uniﬁed model-based and data-driven approach for quadrupedal planning and control to achieve dynamic locomotion over uneven terrain. We utilize on-board proprioceptive and exteroceptive feedback to map sensory information and desired base velocity commands into footstep plans using a reinforcement learning ({RL}) policy. This {RL} policy is trained in simulation over a wide range of procedurally generated terrains. When ran online, the system tracks the generated footstep plans using a model-based motion controller. We evaluate the robustness of our method over a wide variety of complex terrains. It exhibits behaviors which prioritize stability over aggressive locomotion. Additionally, we introduce two ancillary {RL} policies for corrective whole-body motion tracking and recovery control. These policies account for changes in physical parameters and external perturbations. We train and evaluate our framework on a complex quadrupedal system, {ANYmal} version B, and demonstrate transferability to a larger and heavier robot, {ANYmal} C, without requiring retraining.},
  pages        = {2908--2927},
  number       = {5},
  journaltitle = {{IEEE} Transactions on Robotics},
  shortjournal = {{IEEE} Trans. Robot.},
  author       = {Gangapurwala, Siddhant and Geisert, Mathieu and Orsolino, Romeo and Fallon, Maurice and Havoutis, Ioannis},
  urldate      = {2025-07-14},
  date         = {2022-10},
  langid       = {english},
  eprinttype   = {arxiv},
  eprint       = {2012.03094 [cs]},
  keywords     = {Computer Science - Machine Learning, Computer Science - Robotics},
  file         = {2022 - RLOC Terrain-Aware Legged Locomotion using Reinforcement Learning and Optimal Control.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2022 - RLOC Terrain-Aware Legged Locomotion using Reinforcement Learning and Optimal Control.pdf:application/pdf}
}

@inproceedings{duan_sim--real_2022,
  location   = {Philadelphia, {PA}, {USA}},
  title      = {Sim-to-Real Learning of Footstep-Constrained Bipedal Dynamic Walking},
  rights     = {https://doi.org/10.15223/policy-029},
  url        = {https://ieeexplore.ieee.org/document/9812015/},
  doi        = {10.1109/icra46639.2022.9812015},
  abstract   = {Recently, work on reinforcement learning ({RL}) for bipedal robots has successfully learned controllers for a variety of dynamic gaits with robust sim-to-real demonstrations. In order to maintain balance, the learned controllers have full freedom of where to place the feet, resulting in highly robust gaits. In the real world however, the environment will often impose constraints on the feasible footstep locations, typically identiﬁed by perception systems. Unfortunately, most demonstrated {RL} controllers on bipedal robots do not allow for specifying and responding to such constraints. This missing control interface greatly limits the real-world application of current {RL} controllers. In this paper, we aim to maintain the robust and dynamic nature of learned gaits while also respecting footstep constraints imposed externally. We develop an {RL} formulation for training dynamic gait controllers that can respond to speciﬁed touchdown locations. We then successfully demonstrate simulation and sim-to-real performance on the bipedal robot Cassie. In addition, we use supervised learning to induce a transition model for accurately predicting the next touchdown locations that the controller can achieve given the robot’s proprioceptive observations. This model paves the way for integrating the learned controller into a full-order robot locomotion planner that robustly satisﬁes both balance and environmental constraints.},
  eventtitle = {2022 {IEEE} International Conference on Robotics and Automation ({ICRA})},
  pages      = {10428--10434},
  booktitle  = {2022 International Conference on Robotics and Automation ({ICRA})},
  publisher  = {{IEEE}},
  author     = {Duan, Helei and Malik, Ashish and Dao, Jeremy and Saxena, Aseem and Green, Kevin and Siekmann, Jonah and Fern, Alan and Hurst, Jonathan},
  urldate    = {2025-07-14},
  date       = {2022-05-23},
  langid     = {english},
  file       = {2022 - Sim-to-Real Learning of Footstep-Constrained Bipedal Dynamic Walking.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2022 - Sim-to-Real Learning of Footstep-Constrained Bipedal Dynamic Walking.pdf:application/pdf}
}

@article{omar_fast_2022,
  title      = {Fast Convex Visual Foothold Adaptation for Quadrupedal Locomotion},
  url        = {http://arxiv.org/abs/2307.14775},
  doi        = {10.5281/zenodo.7531324},
  abstract   = {This extended abstract provides a short introduction on our recently developed perception-based controller for quadrupedal locomotion. Compared to our previous approach based on Visual Foothold Adaptation ({VFA}) and Model Predictive Control ({MPC}), our new framework combines a fast approximation of the safe foothold regions based on Neural Network regression, followed by a convex decomposition routine in order to generate safe landing areas where the controller can freely optimize the footholds location. The aforementioned framework, which combines prediction, convex decomposition, and {MPC} solution, is tested in simulation on our 140kg hydraulic quadruped robot ({HyQReal}).},
  author     = {Omar, Shafeef and Amatucci, Lorenzo and Turrisi, Giulio and Barasuol, Victor and Semini, Claudio},
  urldate    = {2025-07-14},
  date       = {2022-10-13},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2307.14775 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2023 - Fast Convex Visual Foothold Adaptation for Quadrupedal Locomotion.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2023 - Fast Convex Visual Foothold Adaptation for Quadrupedal Locomotion.pdf:application/pdf}
}

@inproceedings{omar_safesteps_2023,
  location   = {Austin, {TX}, {USA}},
  title      = {{SafeSteps}: Learning Safer Footstep Planning Policies for Legged Robots via Model-Based Priors},
  rights     = {https://doi.org/10.15223/policy-029},
  url        = {https://ieeexplore.ieee.org/document/10375218/},
  doi        = {10.1109/humanoids57100.2023.10375218},
  shorttitle = {{SafeSteps}},
  abstract   = {We present a footstep planning policy for quadrupedal locomotion that is able to directly take into consideration a-priori safety information in its decisions. At its core, a learning process analyzes terrain patches, classifying each landing location by its kinematic feasibility, shin collision, and terrain roughness. This information is then encoded into a small vector representation and passed as an additional state to the footstep planning policy, which furthermore proposes only safe footstep location by applying a masked variant of the Proximal Policy Optimization algorithm. The performance of the proposed approach is shown by comparative simulations and experiments on an electric quadruped robot walking in different rough terrain scenarios. We show that violations of the above safety conditions are greatly reduced both during training and the successive deployment of the policy, resulting in an inherently safer footstep planner. Furthermore, we show how, as a byproduct, fewer reward terms are needed to shape the behavior of the policy, which in return is able to achieve both better final performances and sample efficiency.},
  eventtitle = {2023 {IEEE}-{RAS} 22nd International Conference on Humanoid Robots (Humanoids)},
  pages      = {1--8},
  booktitle  = {2023 {IEEE}-{RAS} 22nd International Conference on Humanoid Robots (Humanoids)},
  publisher  = {{IEEE}},
  author     = {Omar, Shafeef and Amatucci, Lorenzo and Barasuol, Victor and Turrisi, Giulio and Semini, Claudio},
  urldate    = {2025-07-14},
  date       = {2023-12-12},
  langid     = {english},
  file       = {2023 - SafeSteps Learning Safer Footstep Planning Policies for Legged Robots via Model-Based Priors.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2023 - SafeSteps Learning Safer Footstep Planning Policies for Legged Robots via Model-Based Priors.pdf:application/pdf}
}

@misc{shi_terrain-aware_2023,
  title      = {Terrain-Aware Quadrupedal Locomotion via Reinforcement Learning},
  url        = {http://arxiv.org/abs/2310.04675},
  doi        = {10.48550/arXiv.2310.04675},
  abstract   = {In nature, legged animals have developed the ability to adapt to challenging terrains through perception, allowing them to plan safe body and foot trajectories in advance, which leads to safe and energy-efficient locomotion. Inspired by this observation, we present a novel approach to train a Deep Neural Network ({DNN}) policy that integrates proprioceptive and exteroceptive states with a parameterized trajectory generator for quadruped robots to traverse rough terrains. Our key idea is to use a {DNN} policy that can modify the parameters of the trajectory generator, such as foot height and frequency, to adapt to different terrains. To encourage the robot to step on safe regions and save energy consumption, we propose foot terrain reward and lifting foot height reward, respectively. By incorporating these rewards, our method can learn a safer and more efficient terrain-aware locomotion policy that can move a quadruped robot flexibly in any direction. To evaluate the effectiveness of our approach, we conduct simulation experiments on challenging terrains, including stairs, stepping stones, and poles. The simulation results demonstrate that our approach can successfully direct the robot to traverse such tough terrains in any direction. Furthermore, we validate our method on a real legged robot, which learns to traverse stepping stones with gaps over 25.5cm.},
  number     = {{arXiv}:2310.04675},
  publisher  = {{arXiv}},
  author     = {Shi, Haojie and Zhu, Qingxu and Han, Lei and Chi, Wanchao and Li, Tingguang and Meng, Max Q.-H.},
  urldate    = {2025-07-14},
  date       = {2023-10-11},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2310.04675 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2023 - Terrain-Aware Quadrupedal Locomotion via Reinforce.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2023 - Terrain-Aware Quadrupedal Locomotion via Reinforce.pdf:application/pdf}
}

@misc{mitchell_vae-loco_2023,
  title      = {{VAE}-Loco: Versatile Quadruped Locomotion by Learning a Disentangled Gait Representation},
  url        = {http://arxiv.org/abs/2205.01179},
  doi        = {10.48550/arXiv.2205.01179},
  shorttitle = {{VAE}-Loco},
  abstract   = {Quadruped locomotion is rapidly maturing to a degree where robots are able to realise highly dynamic manoeuvres. However, current planners are unable to vary key gait parameters of the in-swing feet midair. In this work we address this limitation and show that it is pivotal in increasing controller robustness by learning a latent space capturing the key stance phases constituting a particular gait. This is achieved via a generative model trained on a single trot style, which encourages disentanglement such that application of a drive signal to a single dimension of the latent state induces holistic plans synthesising a continuous variety of trot styles. We demonstrate that specific properties of the drive signal map directly to gait parameters such as cadence, footstep height and full stance duration. Due to the nature of our approach these synthesised gaits are continuously variable online during robot operation. The use of a generative model facilitates the detection and mitigation of disturbances to provide a versatile and robust planning framework. We evaluate our approach on two versions of the real {ANYmal} quadruped robots and demonstrate that our method achieves a continuous blend of dynamic trot styles whilst being robust and reactive to external perturbations.},
  number     = {{arXiv}:2205.01179},
  publisher  = {{arXiv}},
  author     = {Mitchell, Alexander L. and Merkt, Wolfgang and Geisert, Mathieu and Gangapurwala, Siddhant and Engelcke, Martin and Jones, Oiwi Parker and Havoutis, Ioannis and Posner, Ingmar},
  urldate    = {2025-07-14},
  date       = {2023-07-12},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2205.01179 [cs]},
  keywords   = {Computer Science - Machine Learning, Computer Science - Robotics},
  file       = {2023 - VAE-Loco Versatile Quadruped Locomotion by Learning a Disentangled Gait Representation.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2023 - VAE-Loco Versatile Quadruped Locomotion by Learning a Disentangled Gait Representation.pdf:application/pdf}
}

@misc{zhang_novel_2024,
  title      = {A Novel Multi-Gait Strategy for Stable and Efficient Quadruped Robot Locomotion},
  url        = {http://arxiv.org/abs/2410.09336},
  doi        = {10.48550/arXiv.2410.09336},
  abstract   = {Taking inspiration from the natural gait transition mechanism of quadrupeds, devising a good gait transition strategy is important for quadruped robots to achieve energyefficient locomotion on various terrains and velocities. While previous studies have recognized that gait patterns linked to velocities impact two key factors, the Cost of Transport ({CoT}) and the stability of robot locomotion, only a limited number of studies have effectively combined these factors to design a mechanism that ensures both efficiency and stability in quadruped robot locomotion. In this paper, we propose a multi-gait selection and transition strategy to achieve stable and efficient locomotion across different terrains. Our strategy starts by establishing a gait mapping considering both {CoT} and locomotion stability to guide the gait selection process during locomotion. Then, we achieve gait switching in time by introducing affine transformations for gait parameters and a designed finite state machine to build the switching order. Comprehensive experiments have been conducted on using our strategy with changing terrains and velocities, and the results indicate that our proposed strategy outperforms baseline methods in achieving simultaneous efficiency in locomotion by considering {CoT} and stability.},
  number     = {{arXiv}:2410.09336},
  publisher  = {{arXiv}},
  author     = {Zhang, Daoxun and Chen, Xieyuanli and Zhong, Zhengyu and Xu, Ming and Zheng, Zhiqiang and Lu, Huimin},
  urldate    = {2025-07-14},
  date       = {2024-10-12},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2410.09336 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2024 - A Novel Multi-Gait Strategy for Stable and Efficient Quadruped Robot Locomotion.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2024 - A Novel Multi-Gait Strategy for Stable and Efficient Quadruped Robot Locomotion.pdf:application/pdf}
}

@misc{kaup_review_2024,
  title      = {A Review of Nine Physics Engines for Reinforcement Learning Research},
  url        = {http://arxiv.org/abs/2407.08590},
  doi        = {10.48550/arXiv.2407.08590},
  abstract   = {We present a review of popular simulation engines and frameworks used in reinforcement learning ({RL}) research, aiming to guide researchers in selecting tools for creating simulated physical environments for {RL} and training setups. It evaluates nine frameworks (Brax, Chrono, Gazebo, {MuJoCo}, {ODE}, {PhysX}, {PyBullet}, Webots, and Unity) based on their popularity, feature range, quality, usability, and {RL} capabilities. We highlight the challenges in selecting and utilizing physics engines for {RL} research, including the need for detailed comparisons and an understanding of each framework’s capabilities. Key findings indicate {MuJoCo} as the leading framework due to its performance and flexibility, despite usability challenges. Unity is noted for its ease of use but lacks scalability and simulation fidelity. The study calls for further development to improve simulation engines’ usability and performance and stresses the importance of transparency and reproducibility in {RL} research. This review contributes to the {RL} community by offering insights into the selection process for simulation engines, facilitating informed decision-making.},
  number     = {{arXiv}:2407.08590},
  publisher  = {{arXiv}},
  author     = {Kaup, Michael and Wolff, Cornelius and Hwang, Hyerim and Mayer, Julius and Bruni, Elia},
  urldate    = {2025-07-14},
  date       = {2024-08-23},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2407.08590 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Multiagent Systems},
  file       = {2024 - A Review of Nine Physics Engines for Reinforcement Learning Research.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2024 - A Review of Nine Physics Engines for Reinforcement Learning Research.pdf:application/pdf}
}

@inproceedings{bratta_contactnet_2024,
  title      = {{ContactNet}: Online Multi-Contact Planning for Acyclic Legged Robot Locomotion},
  url        = {http://arxiv.org/abs/2209.15566},
  doi        = {10.1109/UR61395.2024.10597477},
  shorttitle = {{ContactNet}},
  abstract   = {The field of legged robots has seen tremendous progress in the last few years. Locomotion trajectories are commonly generated by optimization algorithms in a Model Predictive Control ({MPC}) loop. To achieve online trajectory optimization, the locomotion community generally makes use of heuristic-based contact planners due to their low computation times and high replanning frequencies. In this work, we propose {ContactNet}, a fast acyclic contact planner based on a multioutput regression neural network. {ContactNet} ranks discretized stepping locations, allowing to quickly choose the best feasible solution, even in complex environments. The low computation time, in the order of 1 ms, enables the execution of the contact planner concurrently with a trajectory optimizer in a {MPC} fashion. In addition, the computational time does not scale up with the configuration of the terrain. We demonstrate the effectiveness of the approach in simulation in different scenarios with the quadruped robot Solo12. To the best knowledge of the authors, this is the first time a contact planner is presented that does not exhibit an increasing computational time on irregular terrains with an increasing number of gaps.},
  author     = {Bratta, Angelo and Meduri, Avadesh and Focchi, Michele and Righetti, Ludovic and Semini, Claudio},
  urldate    = {2025-07-14},
  date       = {2024-06-24},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2209.15566 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2024 - ContactNet Online Multi-Contact Planning for Acyclic Legged Robot Locomotion.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2024 - ContactNet Online Multi-Contact Planning for Acyclic Legged Robot Locomotion.pdf:application/pdf}
}

@inproceedings{gaspard_footstepnet_2024,
  location   = {Abu Dhabi, United Arab Emirates},
  title      = {{FootstepNet}: an Efficient Actor-Critic Method for Fast On-line Bipedal Footstep Planning and Forecasting},
  rights     = {https://doi.org/10.15223/policy-029},
  url        = {https://ieeexplore.ieee.org/document/10802320/},
  doi        = {10.1109/iros58592.2024.10802320},
  shorttitle = {{FootstepNet}},
  abstract   = {Designing a humanoid locomotion controller is challenging and classically split up in sub-problems. Footstep planning is one of those, where the sequence of footsteps is defined. Even in simpler environments, finding a minimal sequence, or even a feasible sequence, yields a complex optimization problem. In the literature, this problem is usually addressed by search-based algorithms (e.g. variants of A*). However, such approaches are either computationally expensive or rely on hand-crafted tuning of several parameters. In this work, at first, we propose an efficient footstep planning method to navigate in local environments with obstacles, based on stateof-the art Deep Reinforcement Learning ({DRL}) techniques, with very low computational requirements for on-line inference. Our approach is heuristic-free and relies on a continuous set of actions to generate feasible footsteps. In contrast, other methods necessitate the selection of a relevant discrete set of actions. Second, we propose a forecasting method, allowing to quickly estimate the number of footsteps required to reach different candidates of local targets. This approach relies on inherent computations made by the actor-critic {DRL} architecture. We demonstrate the validity of our approach with simulation results, and by a deployment on a kid-size humanoid robot during the {RoboCup} 2023 competition.},
  eventtitle = {2024 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS})},
  pages      = {13749--13756},
  booktitle  = {2024 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS})},
  publisher  = {{IEEE}},
  author     = {Gaspard, Clément and Passault, Grégoire and Daniel, Mélodie and Ly, Olivier},
  urldate    = {2025-07-14},
  date       = {2024-10-14},
  langid     = {english},
  file       = {2024 - FootstepNet an Efficient Actor-Critic Method for .pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2024 - FootstepNet an Efficient Actor-Critic Method for .pdf:application/pdf}
}

@article{gao_global_2024,
  title        = {Global footstep planning with greedy and heuristic optimization guided by velocity for biped robot},
  volume       = {238},
  rights       = {https://www.elsevier.com/tdm/userlicense/1.0/},
  issn         = {0957-4174},
  url          = {https://linkinghub.elsevier.com/retrieve/pii/S095741742302300X},
  doi          = {10.1016/j.eswa.2023.121798},
  abstract     = {In order to give full play to the unique movement capabilities of biped robots that are different from traditional mobile robots, and to improve the ability to adapt to the environment, planning an appropriate global footstep sequences is an important way. In this article, we proposed Greedy and Heuristic Quadratic Programming({GHQP}) based on the Quadratic Programming({QP}) method to achieve global footsteps for biped robots. Where {GH}-{QP} consists of greedy terms, heuristic terms and complementary terms. The heuristic term tries to minimize the number of steps in order to obtain the global optimal solution as quickly as possible. At the same time, we use the reference forward speed of the robot’s as the weight coefficient of the heuristic item to achieve the footsteps which is more in line with the walking trend. The greedy term minimizes the mutation caused by the heuristic term, making the footstep more inclined to the local optimum. The complementary term further enhances the greedy term to reduce the mutation between adjacent steps. We verify the effectiveness and high efficiency of our method through two sets of comparative tests. We experimentally validated our method on {BHR}-7P biped robot. The footstep sequences planned by our method adapts to the influence of velocity, and exerts the ability of the robot in the continuous planning process.},
  pages        = {121798},
  journaltitle = {Expert Systems with Applications},
  author       = {Gao, Zhifa and Chen, Xuechao and Yu, Zhangguo and Li, Chao and Han, Lianqiang and Zhang, Runming},
  urldate      = {2025-07-14},
  date         = {2024-03},
  langid       = {english},
  note         = {Publisher: Elsevier {BV}},
  file         = {2024 - Global footstep planning with greedy and heuristic optimization guided by velocity for biped robot.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2024 - Global footstep planning with greedy and heuristic optimization guided by velocity for biped robot.pdf:application/pdf}
}

@misc{asselmeier_hierarchical_2024,
  title      = {Hierarchical Experience-informed Navigation for Multi-modal Quadrupedal Rebar Grid Traversal},
  url        = {http://arxiv.org/abs/2311.08354},
  doi        = {10.48550/arXiv.2311.08354},
  abstract   = {This study focuses on a layered, experience-based, multi-modal contact planning framework for agile quadrupedal locomotion over a constrained rebar environment. To this end, our hierarchical planner incorporates locomotion-specific modules into the high-level contact sequence planner and performs kinodynamically-aware trajectory optimization as the low-level motion planner. Through quantitative analysis of the experience accumulation process and experimental validation of the kinodynamic feasibility of the generated locomotion trajectories, we demonstrate that the planning heuristic of experience offers an effective way of providing candidate footholds for a legged contact planner. Additionally, we introduce a guiding torso path heuristic at the global planning level to enhance the navigation success rate in the presence of environmental obstacles. Our results indicate that the torso-path guided experience accumulation requires significantly fewer offline trials to successfully reach the goal compared to regular experience accumulation. Finally, our planning framework is validated in both dynamics simulations and real hardware implementations on a quadrupedal robot provided by Skymul Inc.},
  number     = {{arXiv}:2311.08354},
  publisher  = {{arXiv}},
  author     = {Asselmeier, Max and Ivanova, Jane and Zhou, Ziyi and Vela, Patricio A. and Zhao, Ye},
  urldate    = {2025-07-14},
  date       = {2024-04-13},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2311.08354 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2024 - Hierarchical Experience-informed Navigation for Multi-modal Quadrupedal Rebar Grid Traversal.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2024 - Hierarchical Experience-informed Navigation for Multi-modal Quadrupedal Rebar Grid Traversal.pdf:application/pdf}
}

@article{han_lifelike_2024,
  title        = {Lifelike Agility and Play in Quadrupedal Robots using Reinforcement Learning and Generative Pre-trained Models},
  volume       = {6},
  issn         = {2522-5839},
  url          = {http://arxiv.org/abs/2308.15143},
  doi          = {10.1038/s42256-024-00861-3},
  abstract     = {Knowledge from animals and humans inspires robotic innovations. Numerous efforts have been made to achieve agile locomotion in quadrupedal robots through classical controllers or reinforcement learning approaches. These methods usually rely on physical models or handcrafted rewards to accurately describe the specific system, rather than on a generalized understanding like animals do. Here we propose a hierarchical framework to construct primitive-, environmental- and strategic-level knowledge that are all pre-trainable, reusable and enrichable for legged robots. The primitive module summarizes knowledge from animal motion data, where, inspired by large pre-trained models in language and image understanding, we introduce deep generative models to produce motor control signals stimulating legged robots to act like real animals. Then, we shape various traversing capabilities at a higher level to align with the environment by reusing the primitive module. Finally, a strategic module is trained focusing on complex downstream tasks by reusing the knowledge from previous levels. We apply the trained hierarchical controllers to the {MAX} robot, a quadrupedal robot developed in-house, to mimic animals, traverse complex obstacles and play in a designed challenging multi-agent chase tag game, where lifelike agility and strategy emerge in the robots.},
  pages        = {787--798},
  number       = {7},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  author       = {Han, Lei and Zhu, Qingxu and Sheng, Jiapeng and Zhang, Chong and Li, Tingguang and Zhang, Yizheng and Zhang, He and Liu, Yuzhen and Zhou, Cheng and Zhao, Rui and Li, Jie and Zhang, Yufeng and Wang, Rui and Chi, Wanchao and Li, Xiong and Zhu, Yonghui and Xiang, Lingzhu and Teng, Xiao and Zhang, Zhengyou},
  urldate      = {2025-07-14},
  date         = {2024-07-05},
  langid       = {english},
  eprinttype   = {arxiv},
  eprint       = {2308.15143 [cs]},
  keywords     = {Computer Science - Artificial Intelligence, Computer Science - Robotics},
  file         = {2024 - Lifelike Agility and Play in Quadrupedal Robots using Reinforcement Learning and Generative Pre-trained Models.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2024 - Lifelike Agility and Play in Quadrupedal Robots using Reinforcement Learning and Generative Pre-trained Models.pdf:application/pdf}
}

@inproceedings{wang_nas_2024,
  location   = {Nancy, France},
  title      = {{NAS}: N-step computation of All Solutions to the footstep planning problem},
  rights     = {https://doi.org/10.15223/policy-029},
  url        = {https://ieeexplore.ieee.org/document/10769878/},
  doi        = {10.1109/humanoids58906.2024.10769878},
  shorttitle = {{NAS}},
  abstract   = {How many ways are there to climb a staircase in a given number of steps? Inﬁnitely many, if we focus on the continuous aspect of the problem. A ﬁnite, possibly large number if we consider the discrete aspect, i.e. on which surface which effectors are going to step and in what order. We introduce {NAS}, an algorithm that considers both aspects simultaneously and computes all the possible solutions to such a contact planning problem, under standard assumptions. To our knowledge {NAS} is the ﬁrst algorithm to produce a globally optimal policy, efﬁciently queried in real time for planning the next footsteps of a humanoid robot.},
  eventtitle = {2024 {IEEE}-{RAS} 23rd International Conference on Humanoid Robots (Humanoids)},
  pages      = {576--583},
  booktitle  = {2024 {IEEE}-{RAS} 23rd International Conference on Humanoid Robots (Humanoids)},
  publisher  = {{IEEE}},
  author     = {Wang, Jiayi and Samadi, Saeid and Wang, Hefan and Fernbach, Pierre and Stasse, Olivier and Vijayakumar, Sethu and Tonneau, Steve},
  urldate    = {2025-07-14},
  date       = {2024-11-22},
  langid     = {english},
  file       = {2024 - NAS N-step computation of All Solutions to the fo.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2024 - NAS N-step computation of All Solutions to the fo.pdf:application/pdf}
}

@article{mittal_orbit_2023,
  title        = {Orbit: A Unified Simulation Framework for Interactive Robot Learning Environments},
  volume       = {8},
  issn         = {2377-3766, 2377-3774},
  url          = {http://arxiv.org/abs/2301.04195},
  doi          = {10.1109/LRA.2023.3270034},
  shorttitle   = {Orbit},
  abstract     = {We present {ORBIT}, a unified and modular framework for robot learning powered by {NVIDIA} Isaac Sim. It offers a modular design to easily and efficiently create robotic environments with photo-realistic scenes and high-fidelity rigid and deformable body simulation. With {ORBIT}, we provide a suite of benchmark tasks of varying difficulty– from singlestage cabinet opening and cloth folding to multi-stage tasks such as room reorganization. To support working with diverse observations and action spaces, we include fixed-arm and mobile manipulators with different physically-based sensors and motion generators. {ORBIT} allows training reinforcement learning policies and collecting large demonstration datasets from hand-crafted or expert solutions in a matter of minutes by leveraging {GPU}-based parallelization. In summary, we offer an open-sourced framework that readily comes with 16 robotic platforms, 4 sensor modalities, 10 motion generators, more than 20 benchmark tasks, and wrappers to 4 learning libraries. With this framework, we aim to support various research areas, including representation learning, reinforcement learning, imitation learning, and task and motion planning. We hope it helps establish interdisciplinary collaborations in these communities, and its modularity makes it easily extensible for more tasks and applications in the future. For videos, documentation, and code: https://isaac-orbit.github.io/.},
  pages        = {3740--3747},
  number       = {6},
  journaltitle = {{IEEE} Robotics and Automation Letters},
  shortjournal = {{IEEE} Robot. Autom. Lett.},
  author       = {Mittal, Mayank and Yu, Calvin and Yu, Qinxi and Liu, Jingzhou and Rudin, Nikita and Hoeller, David and Yuan, Jia Lin and Singh, Ritvik and Guo, Yunrong and Mazhar, Hammad and Mandlekar, Ajay and Babich, Buck and State, Gavriel and Hutter, Marco and Garg, Animesh},
  urldate      = {2025-07-14},
  date         = {2023-06},
  langid       = {english},
  eprinttype   = {arxiv},
  eprint       = {2301.04195 [cs]},
  keywords     = {Computer Science - Artificial Intelligence, Computer Science - Robotics},
  file         = {2024 - ORBIT A Unified Simulation Framework for Interactive Robot Learning Environments.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2024 - ORBIT A Unified Simulation Framework for Interactive Robot Learning Environments.pdf:application/pdf}
}

@misc{asselmeier_steppability-informed_2024,
  title      = {Steppability-informed Quadrupedal Contact Planning through Deep Visual Search Heuristics},
  url        = {http://arxiv.org/abs/2501.00112},
  doi        = {10.48550/arXiv.2501.00112},
  abstract   = {In this work, we introduce a method for predicting environment steppability – the ability of a legged robot platform to place a foothold at a particular location in the local environment – in the image space. This novel environment representation captures this critical geometric property of the local terrain while allowing us to exploit the computational benefits of sensing and planning in the image space. We adapt a primitive shapes-based synthetic data generation scheme to create geometrically rich and diverse simulation scenes and extract ground truth semantic information in order to train a steppability model. We then integrate this steppability model into an existing interleaved graph search and trajectory optimization-based footstep planner to demonstrate how this steppability paradigm can inform footstep planning in complex, unknown environments. We analyze the steppability model performance to demonstrate its validity, and we deploy the perception-informed footstep planner both in offline and online settings to experimentally verify planning performance.},
  number     = {{arXiv}:2501.00112},
  publisher  = {{arXiv}},
  author     = {Asselmeier, Max and Zhao, Ye and Vela, Patricio A.},
  urldate    = {2025-07-14},
  date       = {2024-12-30},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2501.00112 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2024 - Steppability-informed Quadrupedal Contact Planning.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2024 - Steppability-informed Quadrupedal Contact Planning.pdf:application/pdf}
}

@article{wang_when_2024,
  title        = {When and where to step: Terrain-aware real-time footstep location and timing optimization for bipedal robots},
  volume       = {179},
  rights       = {https://www.elsevier.com/tdm/userlicense/1.0/},
  issn         = {0921-8890},
  url          = {https://linkinghub.elsevier.com/retrieve/pii/S092188902400126X},
  doi          = {10.1016/j.robot.2024.104742},
  shorttitle   = {When and where to step},
  abstract     = {Online footstep planning is essential for bipedal walking robots, allowing them to walk in the presence of disturbances and sensory noise. Most of the literature on the topic has focused on optimizing the footstep placement while keeping the step timing constant. In this work, we introduce a footstep planner capable of optimizing footstep placement and step time online. The proposed planner, consisting of an Interior Point Optimizer ({IPOPT}) and an optimizer based on Augmented Lagrangian ({AL}) method with analytical gradient descent, solves the full dynamics of the Linear Inverted Pendulum ({LIP}) model in real time to optimize for footstep location as well as step timing at the rate of 200 Hz. We show that such asynchronous real-time optimization with the {AL} method ({ARTO}-{AL}) provides the required robustness and speed for successful online footstep planning. Furthermore, {ARTO}-{AL} can be extended to plan footsteps in 3D, allowing terrain-aware footstep planning on uneven terrains. Compared to an algorithm with no footstep time adaptation, our proposed {ARTO}-{AL} demonstrates increased stability in simulated walking experiments as it can resist pushes on flat ground and on a 10◦ ramp up to 120 N and 100 N respectively. Videos2 and open-source code3 are released.},
  pages        = {104742},
  journaltitle = {Robotics and Autonomous Systems},
  author       = {Wang, Ke and Hu, Zhaoyang Jacopo and Tisnikar, Peter and Helander, Oskar and Chappell, Digby and Kormushev, Petar},
  urldate      = {2025-07-14},
  date         = {2024-09},
  langid       = {english},
  note         = {Publisher: Elsevier {BV}},
  file         = {2024 - When and where to step Terrain-aware real-time fo.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2024 - When and where to step Terrain-aware real-time fo.pdf:application/pdf}
}

@misc{schperberg_energy-efficient_2025,
  title      = {Energy-Efficient Motion Planner for Legged Robots},
  url        = {http://arxiv.org/abs/2503.06050},
  doi        = {10.48550/arXiv.2503.06050},
  abstract   = {We propose an online motion planner for legged robot locomotion with the primary objective of achieving energy efficiency. The conceptual idea is to leverage a placement set of footstep positions based on the robot’s body position to determine when and how to execute steps. In particular, the proposed planner uses virtual placement sets beneath the hip joints of the legs and executes a step when the foot is outside of such placement set. Furthermore, we propose a parameter design framework that considers both energy-efficiency and robustness measures to optimize the gait by changing the shape of the placement set along with other parameters, such as step height and swing time, as a function of walking speed. We show that the planner produces trajectories that have a low Cost of Transport ({CoT}) and high robustness measure, and evaluate our approach against model-free Reinforcement Learning ({RL}) and motion imitation using biological dog motion priors as the reference. Overall, within low to medium velocity range, we show a 50.4\% improvement in {CoT} and improved robustness over model-free {RL}, our best performing baseline. Finally, we show ability to handle slippery surfaces, gait transitions, and disturbances in simulation and hardware with the Unitree A1 robot.},
  number     = {{arXiv}:2503.06050},
  publisher  = {{arXiv}},
  author     = {Schperberg, Alexander and Menner, Marcel and Cairano, Stefano Di},
  urldate    = {2025-07-14},
  date       = {2025-06-24},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2503.06050 [cs]},
  keywords   = {Computer Science - Robotics, Computer Science - Systems and Control, Electrical Engineering and Systems Science - Systems and Control},
  file       = {2025 - Energy-Efficient Motion Planner for Legged Robots.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2025 - Energy-Efficient Motion Planner for Legged Robots.pdf:application/pdf}
}

@misc{humphreys_learning_2025,
  title      = {Learning to Adapt through Bio-Inspired Gait Strategies for Versatile Quadruped Locomotion},
  url        = {http://arxiv.org/abs/2412.09440},
  doi        = {10.48550/arXiv.2412.09440},
  abstract   = {Legged robots must adapt their gait to navigate unpredictable environments, a challenge that animals master with ease. However, most deep reinforcement learning ({DRL}) approaches to quadruped locomotion rely on a fixed gait, limiting adaptability to changes in terrain and dynamic state. Here we show that integrating three core principles of animal locomotiongait transition strategies, gait memory and real-time motion adjustments enables a {DRL} control framework to fluidly switch among multiple gaits and recover from instability, all without external sensing. Our framework is guided by biomechanicsinspired metrics that capture efficiency, stability and system limits, which are unified to inform optimal gait selection. The resulting framework achieves blind zero-shot deployment across diverse, real-world terrains and substantially significantly outperforms baseline controllers. By embedding biological principles into data-driven control, this work marks a step towards robust, efficient and versatile robotic locomotion, highlighting how animal motor intelligence can shape the next generation of adaptive machines.},
  number     = {{arXiv}:2412.09440},
  publisher  = {{arXiv}},
  author     = {Humphreys, Joseph and Zhou, Chengxu},
  urldate    = {2025-07-14},
  date       = {2025-06-22},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2412.09440 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2025 - Learning to Adapt through Bio-Inspired Gait Strategies for Versatile Quadruped Locomotion.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2025 - Learning to Adapt through Bio-Inspired Gait Strategies for Versatile Quadruped Locomotion.pdf:application/pdf}
}

@article{ha_learning-based_2025,
  title        = {Learning-based legged locomotion: State of the art and future perspectives},
  volume       = {44},
  rights       = {https://journals.sagepub.com/page/policies/text-and-data-mining-license},
  issn         = {0278-3649, 1741-3176},
  url          = {https://journals.sagepub.com/doi/10.1177/02783649241312698},
  doi          = {10.1177/02783649241312698},
  shorttitle   = {Learning-based legged locomotion},
  abstract     = {Legged locomotion holds the premise of universal mobility, a critical capability for many real-world robotic applications. Both model-based and learning-based approaches have advanced the ﬁeld of legged locomotion in the past three decades. In recent years, however, a number of factors have dramatically accelerated progress in learning-based methods, including the rise of deep learning, rapid progress in simulating robotic systems, and the availability of high-performance and affordable hardware. This article aims to give a brief history of the ﬁeld, to summarize recent efforts in learning locomotion skills for quadrupeds, and to provide researchers new to the area with an understanding of the key issues involved. With the recent proliferation of humanoid robots, we further outline the rapid rise of analogous methods for bipedal locomotion. We conclude with a discussion of open problems as well as related societal impact.},
  pages        = {1396--1427},
  number       = {8},
  journaltitle = {The International Journal of Robotics Research},
  author       = {Ha, Sehoon and Lee, Joonho and Van De Panne, Michiel and Xie, Zhaoming and Yu, Wenhao and Khadiv, Majid},
  urldate      = {2025-07-14},
  date         = {2025-07},
  langid       = {english},
  note         = {Publisher: {SAGE} Publications},
  file         = {2025 - Learning-based legged locomotion State of the art and future perspectives.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2025 - Learning-based legged locomotion State of the art and future perspectives.pdf:application/pdf}
}

@article{taouil_non-gaited_2025,
  title        = {Non-Gaited Legged Locomotion With Monte-Carlo Tree Search and Supervised Learning},
  volume       = {10},
  rights       = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
  issn         = {2377-3766, 2377-3774},
  url          = {https://ieeexplore.ieee.org/document/10806593/},
  doi          = {10.1109/lra.2024.3519908},
  abstract     = {Legged robots are able to navigate complex terrains by continuously interacting with the environment through careful selection of contact sequences and timings. However, the combinatorial nature behind contact planning hinders the applicability of such optimization problems on hardware. In this work, we present a novel approach that optimizes gait sequences and respective timings for legged robots in the context of optimization-based controllers through the use of sampling-based methods and supervised learning techniques. We propose to bootstrap the search by learning an optimal value function in order to speed-up the gait planning procedure making it applicable in real-time. To validate our proposed method, we showcase its performance both in simulation and on hardware using a 22 kg electric quadruped robot. The method is assessed on different terrains, under external perturbations, and in comparison to a standard control approach where the gait sequence is ﬁxed a priori.},
  pages        = {1265--1272},
  number       = {2},
  journaltitle = {{IEEE} Robotics and Automation Letters},
  shortjournal = {{IEEE} Robot. Autom. Lett.},
  author       = {Taouil, Ilyass and Amatucci, Lorenzo and Khadiv, Majid and Dai, Angela and Barasuol, Victor and Turrisi, Giulio and Semini, Claudio},
  urldate      = {2025-07-14},
  date         = {2025-02},
  langid       = {english},
  note         = {Publisher: Institute of Electrical and Electronics Engineers ({IEEE})},
  file         = {2025 - Non-Gaited Legged Locomotion With Monte-Carlo Tree Search and Supervised Learning.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2025 - Non-Gaited Legged Locomotion With Monte-Carlo Tree Search and Supervised Learning.pdf:application/pdf}
}

@article{wang_walking_2025,
  title        = {Walking control of humanoid robots based on improved footstep planner and whole-body coordination controller},
  volume       = {19},
  rights       = {https://creativecommons.org/licenses/by/4.0/},
  issn         = {1662-5218},
  url          = {https://www.frontiersin.org/articles/10.3389/fnbot.2025.1538979/full},
  doi          = {10.3389/fnbot.2025.1538979},
  abstract     = {High-speed walking is fundamental for humanoid robots to quickly reach the work site in emergency scenarios. According to biological studies, the coordinated motion of the arms and waist can significantly enhance walking speed and stability in humans. However, existing humanoid robot walking control frameworks predominantly focus on leg control, often overlooking the utilization of upper body joints. In this paper, a novel walking control framework combining the improved footstep planner and the whole-body coordination controller is proposed, aiming to improve the humanoid robot's tracking accuracy of desired speeds and its dynamic walking capability. First, we analyze the issues in traditional footstep planners based on Linear Inverted Pendulum and Model Predictive Control ({LIP}-{MPC}). By reconstructing the footstep optimization problem during walking using the Center-of-Mass ({CoM}) position, we propose an improved footstep planner to enhance the control accuracy of the desired walking speed in humanoid robots. Next, based on biological research, we define a coordinated control strategy for the arms and waist during walking. Specifically, the waist increases the robot's step length, while the arms counteract disturbance momentum and maintain balance. Based on the aforementioned strategy, we design a whole-body coordination controller for the humanoid robot. This controller adopts a novel hierarchical design approach, in which the dynamics and motion controllers for the upper and lower body are modeled and managed separately. This helps avoid the issue of poor control performance caused by multi-task coupling in traditional whole-body controllers. Finally, we integrate these controllers into a novel walking control framework and validate it on the simulation prototype of the humanoid robot Dexbot. Simulation results show that the proposed framework significantly enhances the maximum walking capability of the humanoid robot, demonstrating its feasibility and effectiveness.},
  journaltitle = {Frontiers in Neurorobotics},
  shortjournal = {Front. Neurorobot.},
  author       = {Wang, Xiangji and Guo, Wei and Yin, Siyu and Zhang, Sen and Zha, Fusheng and Li, Mantian and Wang, Pengfei and Li, Xiaolin and Sun, Lining},
  urldate      = {2025-07-14},
  date         = {2025-02-21},
  langid       = {english},
  note         = {Publisher: Frontiers Media {SA}},
  file         = {2025 - Walking control of humanoid robots based on improv.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2025 - Walking control of humanoid robots based on improv.pdf:application/pdf}
}

@misc{amatucci_monte_2022,
  title      = {Monte Carlo Tree Search Gait Planner for Non-Gaited Legged System Control},
  url        = {http://arxiv.org/abs/2205.14277},
  doi        = {10.48550/arXiv.2205.14277},
  abstract   = {In this work, a non-gaited framework for legged system locomotion is presented. The approach decouples the gait sequence optimization by considering the problem as a decision-making process. The redeﬁned contact sequence problem is solved by utilizing a Monte Carlo Tree Search ({MCTS}) algorithm that exploits optimization-based simulations to evaluate the best search direction. The proposed scheme has proven to have a good trade-off between exploration and exploitation of the search space compared to the state-ofthe-art Mixed-Integer Quadratic Programming ({MIQP}). The model predictive control ({MPC}) utilizes the gait generated by the {MCTS} to optimize the ground reaction forces and future footholds position. The simulation results, performed on a quadruped robot, showed that the proposed framework could generate known periodic gait and adapt the contact sequence to the encountered conditions, including external forces and terrain with unknown and variable properties. When tested on robots with different layouts, the system has also shown its reliability.},
  number     = {{arXiv}:2205.14277},
  publisher  = {{arXiv}},
  author     = {Amatucci, Lorenzo and Kim, Joon-Ha and Hwangbo, Jemin and Park, Hae-Won},
  urldate    = {2025-07-15},
  date       = {2022-05-28},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2205.14277 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2022 - Monte Carlo Tree Search Gait Planner for Non-Gaited Legged System Control.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2022 - Monte Carlo Tree Search Gait Planner for Non-Gaited Legged System Control.pdf:application/pdf}
}

@article{mittal2023orbit,
  author  = {Mittal, Mayank and Yu, Calvin and Yu, Qinxi and Liu, Jingzhou and Rudin, Nikita and Hoeller, David and Yuan, Jia Lin and Singh, Ritvik and Guo, Yunrong and Mazhar, Hammad and Mandlekar, Ajay and Babich, Buck and State, Gavriel and Hutter, Marco and Garg, Animesh},
  journal = {IEEE Robotics and Automation Letters},
  title   = {Orbit: A Unified Simulation Framework for Interactive Robot Learning Environments},
  year    = {2023},
  volume  = {8},
  number  = {6},
  pages   = {3740-3747},
  doi     = {10.1109/LRA.2023.3270034}
}

@article{feng2021deep,
  author   = {Feng, Di and Haase-Schütz, Christian and Rosenbaum, Lars and Hertlein, Heinz and Gläser, Claudius and Timm, Fabian and Wiesbeck, Werner and Dietmayer, Klaus},
  journal  = {IEEE Transactions on Intelligent Transportation Systems},
  title    = {Deep Multi-Modal Object Detection and Semantic Segmentation for Autonomous Driving: Datasets, Methods, and Challenges},
  year     = {2021},
  volume   = {22},
  number   = {3},
  pages    = {1341-1360},
  keywords = {Autonomous vehicles;Object detection;Cameras;Sensors;Laser radar;Fuses;Multi-modality;object detection;semantic segmentation;deep learning;autonomous driving},
  doi      = {10.1109/TITS.2020.2972974}
}
@article{Chai2022survey,
	author = {Chai, Hui and Li, Yibin and Song, Rui and Zhang, Guoteng and Zhang, Qin and Liu, Song and Hou, Jinmian and Xin, Yaxian and Yuan, Ming and Zhang, Guoxuan and Yang, Zhiyuan},
	title = {{A survey of the development of quadruped robots: Joint configuration, dynamic locomotion control method and mobile manipulation approach}},
	journal = {Biomimetic Intelligence and Robotics},
	volume = {2},
	number = {1},
	pages = {100029},
	year = {2022},
	month = mar,
	issn = {2667-3797},
	publisher = {Elsevier},
	doi = {10.1016/j.birob.2021.100029}
}
@article{Fan2024survey,
	author = {Fan, Yanan and Pei, Zhongcai and Wang, Chen and Li, Meng and Tang, Zhiyong and Liu, Qinghua},
	title = {{A Review of Quadruped Robots: Structure, Control, and Autonomous Motion}},
	journal = {Adv. Intell. Syst.},
	volume = {6},
	number = {6},
	pages = {2300783},
	year = {2024},
	month = jun,
	issn = {2640-4567},
	publisher = {John Wiley {\&} Sons, Ltd},
	doi = {10.1002/aisy.202300783}
}
@article{Kim2019highly-dynamic,
	author = {Kim, Donghyun and Di Carlo, Jared and Katz, Benjamin and Bledt, Gerardo and Kim, Sangbae},
	title = {{Highly Dynamic Quadruped Locomotion via Whole-Body Impulse Control and Model Predictive Control}},
	journal = {arXiv},
	year = {2019},
	month = sep,
	eprint = {1909.06586},
	doi = {10.48550/arXiv.1909.06586}
}
@article{Geisert2019contact-planning,
	author = {Geisert, Mathieu and Yates, Thomas and Orgen, Asil and Fernbach, Pierre and Havoutis, Ioannis},
	title = {{Contact Planning for the ANYmal Quadruped Robot using an Acyclic Reachability-Based Planner}},
	journal = {arXiv},
	year = {2019},
	month = apr,
	eprint = {1904.08238},
	doi = {10.48550/arXiv.1904.08238}
}
@article{Gurram2024survey,
	author = {Gurram, Maurya and Uttam, Prakash Kumar and Ohol, Shantipal S.},
	title = {{Reinforcement Learning For Quadrupedal Locomotion: Current Advancements And Future Perspectives}},
	journal = {arXiv},
	year = {2024},
	month = oct,
	eprint = {2410.10438},
	doi = {10.48550/arXiv.2410.10438}
}
@article{Bao2024survey,
	author = {Bao, Lingfan and Humphreys, Joseph and Peng, Tianhu and Zhou, Chengxu},
	title = {{Deep Reinforcement Learning for Bipedal Locomotion: A Brief Survey}},
	journal = {arXiv},
	year = {2024},
	month = apr,
	eprint = {2404.17070},
	doi = {10.48550/arXiv.2404.17070}
}
@article{Wang2022Oct,
	author = {Wang, Zhicheng and Wei, Wandi and Xie, Anhuan and Zhang, Yifeng and Wu, Jun and Zhu, Qiuguo},
	title = {{Hybrid Bipedal Locomotion Based on Reinforcement Learning and Heuristics}},
	journal = {Micromachines},
	volume = {13},
	number = {10},
	pages = {1688},
	year = {2022},
	month = oct,
	issn = {2072-666X},
	publisher = {Multidisciplinary Digital Publishing Institute},
	doi = {10.3390/mi13101688}
}
@article{Meng2023Mar,
	author = {Meng, Yue and Fan, Chuchu},
	title = {{Hybrid Systems Neural Control with Region-of-Attraction Planner}},
	journal = {arXiv},
	year = {2023},
	month = mar,
	eprint = {2303.10327},
	doi = {10.48550/arXiv.2303.10327}
}
@article{Wensing2022Nov,
	author = {Wensing, Patrick M. and Posa, Michael and Hu, Yue and Escande, Adrien and Mansard, Nicolas and Del Prete, Andrea},
	title = {{Optimization-Based Control for Dynamic Legged Robots}},
	journal = {arXiv},
	year = {2022},
	month = nov,
	eprint = {2211.11644},
	doi = {10.48550/arXiv.2211.11644}
}
@article{Makoviychuk_isaac_2021,
	author = {Makoviychuk, Viktor and Wawrzyniak, Lukasz and Guo, Yunrong and Lu, Michelle and Storey, Kier and Macklin, Miles and Hoeller, David and Rudin, Nikita and Allshire, Arthur and Handa, Ankur and State, Gavriel},
	title = {{Isaac Gym: High Performance GPU-Based Physics Simulation For Robot Learning}},
	journal = {arXiv},
	year = {2021},
	month = aug,
	eprint = {2108.10470},
	doi = {10.48550/arXiv.2108.10470}
}
@article{Schulman_proximal_2017,
	author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	title = {{Proximal Policy Optimization Algorithms}},
	journal = {arXiv},
	year = {2017},
	month = jul,
	eprint = {1707.06347},
	doi = {10.48550/arXiv.1707.06347}
}
@article{bishop_relu_2023,
	author = {Bishop, Arun L. and Zhang, John Z. and Gurumurthy, Swaminathan and Tracy, Kevin and Manchester, Zachary},
	title = {{ReLU-QP: A GPU-Accelerated Quadratic Programming Solver for Model-Predictive Control}},
	journal = {arXiv},
	year = {2023},
	month = nov,
	eprint = {2311.18056},
	doi = {10.48550/arXiv.2311.18056}
}
@phdthesis{Plancher22Dissertation,
  title={GPU Acceleration for Real-time, Whole-body, Nonlinear Model Predictive Control},
  author={Plancher, Brian},
  school={Harvard University},
  year={2022},
  address = {Cambridge, MA, USA},
  month={April}
}