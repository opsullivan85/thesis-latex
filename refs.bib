
@article{kalakrishnan_learning_2011,
  title        = {Learning, planning, and control for quadruped locomotion over challenging                 terrain},
  volume       = {30},
  rights       = {https://journals.sagepub.com/page/policies/text-and-data-mining-license},
  issn         = {0278-3649, 1741-3176},
  url          = {https://journals.sagepub.com/doi/10.1177/0278364910388677},
  doi          = {10.1177/0278364910388677},
  abstract     = {We present a control architecture for fast quadruped locomotion over rough terrain. We approach the problem by decomposing it into many sub-systems, in which we apply state-of-the-art learning, planning, optimization, and control techniques to achieve robust, fast locomotion. Unique features of our control strategy include: (1) a system that learns optimal foothold choices from expert demonstration using terrain templates, (2) a body trajectory optimizer based on the {ZeroMoment} Point ({ZMP}) stability criterion, and (3) a ﬂoating-base inverse dynamics controller that, in conjunction with force control, allows for robust, compliant locomotion over unperceived obstacles. We evaluate the performance of our controller by testing it on the {LittleDog} quadruped robot, over a wide variety of rough terrains of varying difﬁculty levels. The terrain that the robot was tested on includes rocks, logs, steps, barriers, and gaps, with obstacle sizes up to the leg length of the robot. We demonstrate the generalization ability of this controller by presenting results from testing performed by an independent external test team on terrain that has never been shown to us.},
  pages        = {236--258},
  number       = {2},
  year         = {2011},
  journaltitle = {The International Journal of Robotics Research},
  author       = {Kalakrishnan, Mrinal and Buchli, Jonas and Pastor, Peter and Mistry, Michael and Schaal, Stefan},
  urldate      = {2025-07-14},
  date         = {2011-02},
  langid       = {english},
  journal      = {Int. J. Rob. Res.},
  note         = {Publisher: {SAGE} Publications},
  file         = {2011 - Learning, planning, and control for quadruped locomotion over challenging terrain.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2011 - Learning, planning, and control for quadruped locomotion over challenging terrain.pdf:application/pdf}
}

@article{zucker_optimization_2011,
	author = {Zucker, Matt and Ratliff, Nathan and Stolle, Martin and Chestnutt, Joel and Bagnell, J. Andrew and Atkeson, Christopher G. and Kuffner, James},
	title = {{Optimization and learning for rough terrain legged locomotion}},
	journal = {Int. J. Rob. Res.},
	volume = {30},
	number = {2},
	pages = {175--191},
	year = {2011},
	month = jan,
	issn = {0278-3649},
	publisher = {SAGE Publications Ltd STM},
	doi = {10.1177/0278364910392608}
}

@inproceedings{todorov_mujoco_2012,
  location   = {Vilamoura-Algarve, Portugal},
  title      = {{MuJoCo}: A physics engine for model-based control},
  url        = {http://ieeexplore.ieee.org/document/6386109/},
  doi        = {10.1109/iros.2012.6386109},
  shorttitle = {{MuJoCo}},
  abstract   = {We describe a new physics engine tailored to model-based control. Multi-joint dynamics are represented in generalized coordinates and computed via recursive algorithms. Contact responses are computed via efﬁcient new algorithms we have developed, based on the modern velocity-stepping approach which avoids the difﬁculties with spring-dampers. Models are speciﬁed using either a high-level C++ {API} or an intuitive {XML} ﬁle format. A built-in compiler transforms the user model into an optimized data structure used for runtime computation. The engine can compute both forward and inverse dynamics. The latter are well-deﬁned even in the presence of contacts and equality constraints. The model can include tendon wrapping as well as actuator activation states (e.g. pneumatic cylinders or muscles). To facilitate optimal control applications and in particular sampling and ﬁnite differencing, the dynamics can be evaluated for different states and controls in parallel. Around 400,000 dynamics evaluations per second are possible on a 12-core machine, for a 3D homanoid with 18 dofs and 6 active contacts. We have already used the engine in a number of control applications. It will soon be made publicly available.},
  eventtitle = {2012 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS} 2012)},
  booktitle  = {2012 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems},
  publisher  = {{IEEE}},
  author     = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  urldate    = {2025-07-14},
  date       = {2012-10},
  langid     = {english},
  file       = {2012 - MuJoCo A physics engine for model-based control.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2012 - MuJoCo A physics engine for model-based control.pdf:application/pdf}
}

@article{peng_deeploco_2017,
	author = {Peng, Xue Bin and Berseth, Glen and Yin, Kangkang and Van De Panne, Michiel},
	title = {{DeepLoco: dynamic locomotion skills using hierarchical deep reinforcement learning}},
	journal = {ACM Trans. Graph.},
	volume = {36},
	number = {4},
	pages = {1--13},
	year = {2017},
	month = jul,
	issn = {0730-0301},
	publisher = {Association for Computing Machinery},
	doi = {10.1145/3072959.3073602}
}

@article{winkler_gait_2018,
	author = {Winkler, Alexander W. and Bellicoso, C. Dario and Hutter, Marco and Buchli, Jonas},
	title = {{Gait and Trajectory Optimization for Legged Systems Through Phase-Based End-Effector Parameterization}},
	journal = {IEEE Rob. Autom. Lett.},
	volume = {3},
	number = {3},
	pages = {1560--1567},
	year = {2018},
	month = feb,
	publisher = {IEEE},
	doi = {10.1109/LRA.2018.2798285}
}

@article{villarreal_fast_2019,
	author = {Villarreal, Octavio and Barasuol, Victor and Camurri, Marco and Franceschi, Luca and Focchi, Michele and Pontil, Massimiliano and Caldwell, Darwin G. and Semini, Claudio},
	title = {{Fast and Continuous Foothold Adaptation for Dynamic Locomotion through CNNs}},
	journal = {arXiv},
	year = {2018},
	month = sep,
	eprint = {1809.09759},
	doi = {10.1109/LRA.2019.2899434}
}

@misc{tsounis_deepgait_2020,
  title      = {{DeepGait}: Planning and Control of Quadrupedal Gaits using Deep Reinforcement Learning},
  url        = {http://arxiv.org/abs/1909.08399},
  doi        = {10.48550/arXiv.1909.08399},
  shorttitle = {{DeepGait}},
  abstract   = {This paper addresses the problem of legged locomotion in non-ﬂat terrain. As legged robots such as quadrupeds are to be deployed in terrains with geometries which are difﬁcult to model and predict, the need arises to equip them with the capability to generalize well to unforeseen situations. In this work, we propose a novel technique for training neuralnetwork policies for terrain-aware locomotion, which combines state-of-the-art methods for model-based motion planning and reinforcement learning. Our approach is centered on formulating Markov decision processes using the evaluation of dynamic feasibility criteria in place of physical simulation. We thus employ policy-gradient methods to independently train policies which respectively plan and execute foothold and base motions in 3D environments using both proprioceptive and exteroceptive measurements. We apply our method within a challenging suite of simulated terrain scenarios which contain features such as narrow bridges, gaps and stepping-stones, and train policies which succeed in locomoting effectively in all cases.},
  number     = {{arXiv}:1909.08399},
  publisher  = {{arXiv}},
  author     = {Tsounis, Vassilios and Alge, Mitja and Lee, Joonho and Farshidian, Farbod and Hutter, Marco},
  urldate    = {2025-07-14},
  date       = {2020-01-31},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {1909.08399 [cs]},
  keywords   = {Computer Science - Machine Learning, Computer Science - Robotics},
  file       = {2020 - DeepGait Planning and Control of Quadrupedal Gaits using Deep Reinforcement Learning.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2020 - DeepGait Planning and Control of Quadrupedal Gaits using Deep Reinforcement Learning.pdf:application/pdf}
}

@misc{meduri_deepq_2020,
  title      = {{DeepQ} Stepper: A framework for reactive dynamic walking on uneven terrain},
  url        = {http://arxiv.org/abs/2010.14834},
  doi        = {10.48550/arXiv.2010.14834},
  shorttitle = {{DeepQ} Stepper},
  abstract   = {Reactive stepping and push recovery for biped robots is often restricted to ﬂat terrains because of the difﬁculty in computing capture regions for nonlinear dynamic models. In this paper, we address this limitation by using reinforcement learning to approximately learn the 3D capture region for such systems. We propose a novel 3D reactive stepper, The {DeepQ} stepper, that computes optimal step locations for walking at different velocities using the 3D capture regions approximated by the action-value function. We demonstrate the ability of the approach to learn stepping with a simpliﬁed 3D pendulum model and a full robot dynamics. Further, the stepper achieves a higher performance when it learns approximate capture regions while taking into account the entire dynamics of the robot that are often ignored in existing reactive steppers based on simpliﬁed models. The {DeepQ} stepper can handle non convex terrain with obstacles, walk on restricted surfaces like stepping stones and recover from external disturbances for a constant computational cost.},
  number     = {{arXiv}:2010.14834},
  publisher  = {{arXiv}},
  author     = {Meduri, Avadesh and Khadiv, Majid and Righetti, Ludovic},
  urldate    = {2025-07-14},
  date       = {2020-10-28},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2010.14834 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2020 - DeepQ Stepper A framework for reactive dynamic walking on uneven terrain.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2020 - DeepQ Stepper A framework for reactive dynamic walking on uneven terrain.pdf:application/pdf}
}

@article{lee_learning_2020,
	author = {Lee, Joonho and Hwangbo, Jemin and Wellhausen, Lorenz and Koltun, Vladlen and Hutter, Marco},
	title = {{Learning Quadrupedal Locomotion over Challenging Terrain}},
	journal = {arXiv},
	year = {2020},
	month = oct,
	eprint = {2010.11251},
	doi = {10.1126/scirobotics.abc5986}
}

@inproceedings{zhu_off-road_2020,
  title      = {Off-road Autonomous Vehicles Traversability Analysis and Trajectory Planning Based on Deep Inverse Reinforcement Learning},
  url        = {http://arxiv.org/abs/1909.06953},
  doi        = {10.1109/IV47402.2020.9304721},
  abstract   = {Terrain traversability analysis is a fundamental issue to achieve the autonomy of a robot at off-road environments. Geometry-based and appearance-based methods have been studied in decades, while behavior-based methods exploiting learning from demonstration ({LfD}) are new trends. Behaviorbased methods learn cost functions that guide trajectory planning in compliance with experts’ demonstrations, which can be more scalable to various scenes and driving behaviors. This research proposes a method of off-road traversability analysis and trajectory planning using Deep Maximum Entropy Inverse Reinforcement Learning. To incorporate the vehicle’s kinematics while solving the problem of exponential increase of state-space complexity, two convolutional neural networks, i.e., {RL} {ConvNet} and Svf {ConvNet}, are developed to encode kinematics into convolution kernels and achieve efﬁcient forward reinforcement learning. We conduct experiments in off-road environments. Scene maps are generated using 3D {LiDAR} data, and expert demonstrations are either the vehicle’s real driving trajectories at the scene or synthesized ones to represent speciﬁc behaviors such as crossing negative obstacles. Different cost functions of traversability analysis are learned and tested at various scenes of capability in guiding the trajectory planning of different behaviors. We also demonstrate the peformance and computation efﬁciency of the proposed method.},
  pages      = {971--977},
  author     = {Zhu, Zeyu and Li, Nan and Sun, Ruoyu and Zhao, Huijing and Xu, Donghao},
  urldate    = {2025-07-14},
  date       = {2020-10-19},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {1909.06953 [cs]},
  keywords   = {Computer Science - Machine Learning, Computer Science - Robotics},
  file       = {2020 - Off-road Autonomous Vehicles Traversability Analys.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2020 - Off-road Autonomous Vehicles Traversability Analys.pdf:application/pdf}
}

@article{hong_real-time_2020,
  title        = {Real-Time Feasible Footstep Planning for Bipedal Robots in Three-Dimensional Environments Using Particle Swarm Optimization},
  volume       = {25},
  rights       = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
  issn         = {1083-4435, 1941-014X},
  url          = {https://ieeexplore.ieee.org/document/8911501/},
  doi          = {10.1109/tmech.2019.2955701},
  abstract     = {Footstep planning in various threedimensional environments is formulated as an optimization problem, which is solved using a particle swarm optimization. The objective function for optimization is designed to achieve real-time footstep planning considering arrival at the goal with effective not only foot placements but also walking periods, kinematic constraints: obstacle avoidance and hardware limitations, and dynamic constraints for the bipedal dynamics: stability while walking and feasibility of footsteps in a walking pattern generator. Speciﬁcally, optimization objectives are to minimize remaining distance to the goal, lateral movement, rotational movement, and walking period variation. Three penalties are also considered depending on the situations. The ﬁrst penalty is for obstacle collision avoidance along with prevention of unstable walking due to excessive footstep height variation. The second penalty is for walking satisfying stable zero-moment point condition along with the foot collision avoidance. The third penalty is for feasible footstep planning in a walking pattern generator. Any approximation or precomputation is not required for the proposed footstep planning method. The validity of the proposed method is veriﬁed through experiments in various 3-D environments with static and dynamic obstacles.},
  pages        = {429--437},
  number       = {1},
  journaltitle = {{IEEE}/{ASME} Transactions on Mechatronics},
  shortjournal = {{IEEE}/{ASME} Trans. Mechatron.},
  author       = {Hong, Young-Dae and Lee, Bumjoo},
  urldate      = {2025-07-14},
  date         = {2020-02},
  langid       = {english},
  note         = {Publisher: Institute of Electrical and Electronics Engineers ({IEEE})},
  file         = {2020 - Real-Time Feasible Footstep Planning for Bipedal Robots in Three-Dimensional Environments Using Particle Swarm Optimization.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2020 - Real-Time Feasible Footstep Planning for Bipedal Robots in Three-Dimensional Environments Using Particle Swarm Optimization.pdf:application/pdf}
}

@misc{siekmann_blind_2021,
  title      = {Blind Bipedal Stair Traversal via Sim-to-Real Reinforcement Learning},
  url        = {http://arxiv.org/abs/2105.08328},
  doi        = {10.48550/arXiv.2105.08328},
  abstract   = {Accurate and precise terrain estimation is a difﬁcult problem for robot locomotion in real-world environments. Thus, it is useful to have systems that do not depend on accurate estimation to the point of fragility. In this paper, we explore the limits of such an approach by investigating the problem of traversing stair-like terrain without any external perception or terrain models on a bipedal robot. For such blind bipedal platforms, the problem appears difﬁcult (even for humans) due to the surprise elevation changes. Our main contribution is to show that sim-to-real reinforcement learning ({RL}) can achieve robust locomotion over stair-like terrain on the bipedal robot Cassie using only proprioceptive feedback. Importantly, this only requires modifying an existing ﬂat-terrain training {RL} framework to include stair-like terrain randomization, without any changes in reward function. To our knowledge, this is the ﬁrst controller for a bipedal, human-scale robot capable of reliably traversing a variety of real-world stairs and other stair-like disturbances using only proprioception.},
  number     = {{arXiv}:2105.08328},
  publisher  = {{arXiv}},
  author     = {Siekmann, Jonah and Green, Kevin and Warila, John and Fern, Alan and Hurst, Jonathan},
  urldate    = {2025-07-14},
  date       = {2021-05-18},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2105.08328 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2021 - Blind Bipedal Stair Traversal via Sim-to-Real Rein.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2021 - Blind Bipedal Stair Traversal via Sim-to-Real Rein.pdf:application/pdf}
}

@incollection{xie_glide_2023,
	author = {Xie, Zhaoming and Da, Xingye and Babich, Buck and Garg, Animesh and van de Panne, Michiel},
	title = {{GLiDE: Generalizable Quadrupedal Locomotion in Diverse Environments with a Centroidal Model}},
	booktitle = {{Algorithmic Foundations of Robotics XV}},
	journal = {SpringerLink},
	pages = {523--539},
	year = {2022},
	month = dec,
	issn = {2511-1264},
	isbn = {978-3-031-21090-7},
	publisher = {Springer},
	address = {Cham, Switzerland},
	doi = {10.1007/978-3-031-21090-7_31}
}

@article{rudin_learning_nodate,
  title    = {Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement Learning},
  abstract = {In this work, we present and study a training set-up that achieves fast policy generation for real-world robotic tasks by using massive parallelism on a single workstation {GPU}. We analyze and discuss the impact of different training algorithm components in the massively parallel regime on the ﬁnal policy performance and training times. In addition, we present a novel game-inspired curriculum that is well suited for training with thousands of simulated robots in parallel. We evaluate the approach by training the quadrupedal robot {ANYmal} to walk on challenging terrain. The parallel approach allows training policies for ﬂat terrain in under four minutes, and in twenty minutes for uneven terrain. This represents a speedup of multiple orders of magnitude compared to previous work. Finally, we transfer the policies to the real robot to validate the approach. We open-source our training code to help accelerate further research in the ﬁeld of learned legged locomotion: https://leggedrobotics.github.io/legged\_gym/.},
  author   = {Rudin, Nikita and Hoeller, David and Hutter, Marco and Reist, Philipp},
  langid   = {english},
  file     = {2021 - Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement Learning.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2021 - Learning to Walk in Minutes Using Massively Parallel Deep Reinforcement Learning.pdf:application/pdf}
}

@inproceedings{wellhausen_rough_2021,
  location   = {Prague, Czech Republic},
  title      = {Rough Terrain Navigation for Legged Robots using Reachability Planning and Template Learning},
  rights     = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/{IEEE}.html},
  url        = {https://ieeexplore.ieee.org/document/9636358/},
  doi        = {10.1109/iros51168.2021.9636358},
  abstract   = {Navigation planning for legged robots has distinct challenges compared to wheeled and tracked systems due to the ability to lift legs off the ground and step over obstacles. While most navigation planners assume a ﬁxed traversability value for a single terrain patch, we overcome this limitation by proposing a reachability-based navigation planner for legged robots. We approximate the robot morphology by a set of reachability and body volumes, assuming that the reachability volumes need to always be in contact with the environment, while the body should be contact-free. We train a convolutional neural network to predict foothold scores which are used to restrict geometries which are considered suitable to step on. Using this representation, we propose a navigation planner based on probabilistic roadmaps. Through validation of only low-cost graph edges during graph expansion and an adaptive sampling scheme based on roadmap node density, we achieve real-time performance with fast update rates even in cluttered and narrow environments. We thoroughly validate the proposed navigation planner in simulation and demonstrate its performance in real-world experiments on the quadruped {ANYmal}.},
  eventtitle = {2021 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS})},
  pages      = {6914--6921},
  booktitle  = {2021 {IEEE}/{RSJ} International Conference on Intelligent Robots and Systems ({IROS})},
  publisher  = {{IEEE}},
  author     = {Wellhausen, Lorenz and Hutter, Marco},
  urldate    = {2025-07-14},
  date       = {2021-09-27},
  langid     = {english},
  file       = {2021 - Rough Terrain Navigation for Legged Robots using R.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2021 - Rough Terrain Navigation for Legged Robots using R.pdf:application/pdf}
}

@misc{siekmann_sim--real_2021,
  title      = {Sim-to-Real Learning of All Common Bipedal Gaits via Periodic Reward Composition},
  url        = {http://arxiv.org/abs/2011.01387},
  doi        = {10.48550/arXiv.2011.01387},
  abstract   = {We study the problem of realizing the full spectrum of bipedal locomotion on a real robot with sim-to-real reinforcement learning ({RL}). A key challenge of learning legged locomotion is describing different gaits, via reward functions, in a way that is intuitive for the designer and speciﬁc enough to reliably learn the gait across different initial random seeds or hyperparameters. A common approach is to use reference motions (e.g. trajectories of joint positions) to guide learning. However, ﬁnding high-quality reference motions can be difﬁcult and the trajectories themselves narrowly constrain the space of learned motion. At the other extreme, reference-free reward functions are often underspeciﬁed (e.g. move forward) leading to massive variance in policy behavior, or are the product of signiﬁcant reward-shaping via trial-and-error, making them exclusive to speciﬁc gaits. In this work, we propose a rewardspeciﬁcation framework based on composing simple probabilistic periodic costs on basic forces and velocities. We instantiate this framework to deﬁne a parametric reward function with intuitive settings for all common bipedal gaits - standing, walking, hopping, running, and skipping. Using this function we demonstrate successful sim-to-real transfer of the learned gaits to the bipedal robot Cassie, as well as a generic policy that can transition between all of the two-beat gaits.},
  number     = {{arXiv}:2011.01387},
  publisher  = {{arXiv}},
  author     = {Siekmann, Jonah and Godse, Yesh and Fern, Alan and Hurst, Jonathan},
  urldate    = {2025-07-14},
  date       = {2021-03-11},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2011.01387 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2021 - Sim-to-Real Learning of All Common Bipedal Gaits via Periodic Reward Composition.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2021 - Sim-to-Real Learning of All Common Bipedal Gaits via Periodic Reward Composition.pdf:application/pdf}
}

@misc{grandia_perceptive_2022,
  title      = {Perceptive Locomotion through Nonlinear Model Predictive Control},
  url        = {http://arxiv.org/abs/2208.08373},
  doi        = {10.48550/arXiv.2208.08373},
  abstract   = {Dynamic locomotion in rough terrain requires accurate foot placement, collision avoidance, and planning of the underactuated dynamics of the system. Reliably optimizing for such motions and interactions in the presence of imperfect and often incomplete perceptive information is challenging. We present a complete perception, planning, and control pipeline, that can optimize motions for all degrees of freedom of the robot in real-time. To mitigate the numerical challenges posed by the terrain a sequence of convex inequality constraints is extracted as local approximations of foothold feasibility and embedded into an online model predictive controller. Steppability classiﬁcation, plane segmentation, and a signed distance ﬁeld are precomputed per elevation map to minimize the computational effort during the optimization. A combination of multipleshooting, real-time iteration, and a ﬁlter-based line-search are used to solve the formulated problem reliably and at high rate. We validate the proposed method in scenarios with gaps, slopes, and stepping stones in simulation and experimentally on the {ANYmal} quadruped platform, resulting in state-of-the-art dynamic climbing.},
  number     = {{arXiv}:2208.08373},
  publisher  = {{arXiv}},
  author     = {Grandia, Ruben and Jenelten, Fabian and Yang, Shaohui and Farshidian, Farbod and Hutter, Marco},
  urldate    = {2025-07-14},
  date       = {2022-08-17},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2208.08373 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2022 - Perceptive Locomotion through Nonlinear Model Predictive Control.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2022 - Perceptive Locomotion through Nonlinear Model Predictive Control.pdf:application/pdf}
}

@article{gangapurwala_rloc_2022,
  title        = {{RLOC}: Terrain-Aware Legged Locomotion using Reinforcement Learning and Optimal Control},
  volume       = {38},
  issn         = {1552-3098, 1941-0468},
  url          = {http://arxiv.org/abs/2012.03094},
  doi          = {10.1109/TRO.2022.3172469},
  shorttitle   = {{RLOC}},
  abstract     = {We present a uniﬁed model-based and data-driven approach for quadrupedal planning and control to achieve dynamic locomotion over uneven terrain. We utilize on-board proprioceptive and exteroceptive feedback to map sensory information and desired base velocity commands into footstep plans using a reinforcement learning ({RL}) policy. This {RL} policy is trained in simulation over a wide range of procedurally generated terrains. When ran online, the system tracks the generated footstep plans using a model-based motion controller. We evaluate the robustness of our method over a wide variety of complex terrains. It exhibits behaviors which prioritize stability over aggressive locomotion. Additionally, we introduce two ancillary {RL} policies for corrective whole-body motion tracking and recovery control. These policies account for changes in physical parameters and external perturbations. We train and evaluate our framework on a complex quadrupedal system, {ANYmal} version B, and demonstrate transferability to a larger and heavier robot, {ANYmal} C, without requiring retraining.},
  pages        = {2908--2927},
  number       = {5},
  journaltitle = {{IEEE} Transactions on Robotics},
  shortjournal = {{IEEE} Trans. Robot.},
  author       = {Gangapurwala, Siddhant and Geisert, Mathieu and Orsolino, Romeo and Fallon, Maurice and Havoutis, Ioannis},
  urldate      = {2025-07-14},
  date         = {2022-10},
  langid       = {english},
  eprinttype   = {arxiv},
  eprint       = {2012.03094 [cs]},
  keywords     = {Computer Science - Machine Learning, Computer Science - Robotics},
  file         = {2022 - RLOC Terrain-Aware Legged Locomotion using Reinforcement Learning and Optimal Control.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2022 - RLOC Terrain-Aware Legged Locomotion using Reinforcement Learning and Optimal Control.pdf:application/pdf}
}

@incollection{duan_sim--real_2022,
	author = {Duan, Helei and Malik, Ashish and Dao, Jeremy and Saxena, Aseem and Green, Kevin and Siekmann, Jonah},
	title = {{Sim-to-Real Learning of Footstep-Constrained Bipedal Dynamic Walking}},
	booktitle = {{2022 International Conference on Robotics and Automation (ICRA)}},
	journal = {Published in: 2022 International Conference on Robotics and Automation (ICRA)},
	pages = {23--27},
  year = {2022},
	publisher = {IEEE},
	doi = {10.1109/ICRA46639.2022.9812015}
}

@article{omar_fast_2022,
	author = {Omar, Shafeef and Amatucci, Lorenzo and Turrisi, Giulio and Barasuol, Victor and Semini, Claudio},
	title = {{Fast Convex Visual Foothold Adaptation for Quadrupedal Locomotion}},
	journal = {arXiv},
	year = {2023},
	month = jul,
	eprint = {2307.14775},
	doi = {10.5281/zenodo.7531324}
}

@incollection{omar_safesteps_2023,
	author = {Omar, Shafeef and Amatucci, Lorenzo and Barasuol, Victor and Turrisi, Giulio and Semini, Claudio},
	title = {{SafeSteps: Learning Safer Footstep Planning Policies for Legged Robots via Model-Based Priors}},
	booktitle = {{2023 IEEE-RAS 22nd International Conference on Humanoid Robots (Humanoids)}},
	journal = {Published in: 2023 IEEE-RAS 22nd International Conference on Humanoid Robots (Humanoids)},
	pages = {12--14},
  year = {2023},
	publisher = {IEEE},
	doi = {10.1109/Humanoids57100.2023.10375218}
}

@misc{shi_terrain-aware_2023,
  title      = {Terrain-Aware Quadrupedal Locomotion via Reinforcement Learning},
  url        = {http://arxiv.org/abs/2310.04675},
  doi        = {10.48550/arXiv.2310.04675},
  abstract   = {In nature, legged animals have developed the ability to adapt to challenging terrains through perception, allowing them to plan safe body and foot trajectories in advance, which leads to safe and energy-efficient locomotion. Inspired by this observation, we present a novel approach to train a Deep Neural Network ({DNN}) policy that integrates proprioceptive and exteroceptive states with a parameterized trajectory generator for quadruped robots to traverse rough terrains. Our key idea is to use a {DNN} policy that can modify the parameters of the trajectory generator, such as foot height and frequency, to adapt to different terrains. To encourage the robot to step on safe regions and save energy consumption, we propose foot terrain reward and lifting foot height reward, respectively. By incorporating these rewards, our method can learn a safer and more efficient terrain-aware locomotion policy that can move a quadruped robot flexibly in any direction. To evaluate the effectiveness of our approach, we conduct simulation experiments on challenging terrains, including stairs, stepping stones, and poles. The simulation results demonstrate that our approach can successfully direct the robot to traverse such tough terrains in any direction. Furthermore, we validate our method on a real legged robot, which learns to traverse stepping stones with gaps over 25.5cm.},
  number     = {{arXiv}:2310.04675},
  publisher  = {{arXiv}},
  author     = {Shi, Haojie and Zhu, Qingxu and Han, Lei and Chi, Wanchao and Li, Tingguang and Meng, Max Q.-H.},
  urldate    = {2025-07-14},
  date       = {2023-10-11},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2310.04675 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2023 - Terrain-Aware Quadrupedal Locomotion via Reinforce.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2023 - Terrain-Aware Quadrupedal Locomotion via Reinforce.pdf:application/pdf}
}

@misc{mitchell_vae-loco_2023,
  title      = {{VAE}-Loco: Versatile Quadruped Locomotion by Learning a Disentangled Gait Representation},
  url        = {http://arxiv.org/abs/2205.01179},
  doi        = {10.48550/arXiv.2205.01179},
  shorttitle = {{VAE}-Loco},
  abstract   = {Quadruped locomotion is rapidly maturing to a degree where robots are able to realise highly dynamic manoeuvres. However, current planners are unable to vary key gait parameters of the in-swing feet midair. In this work we address this limitation and show that it is pivotal in increasing controller robustness by learning a latent space capturing the key stance phases constituting a particular gait. This is achieved via a generative model trained on a single trot style, which encourages disentanglement such that application of a drive signal to a single dimension of the latent state induces holistic plans synthesising a continuous variety of trot styles. We demonstrate that specific properties of the drive signal map directly to gait parameters such as cadence, footstep height and full stance duration. Due to the nature of our approach these synthesised gaits are continuously variable online during robot operation. The use of a generative model facilitates the detection and mitigation of disturbances to provide a versatile and robust planning framework. We evaluate our approach on two versions of the real {ANYmal} quadruped robots and demonstrate that our method achieves a continuous blend of dynamic trot styles whilst being robust and reactive to external perturbations.},
  number     = {{arXiv}:2205.01179},
  publisher  = {{arXiv}},
  author     = {Mitchell, Alexander L. and Merkt, Wolfgang and Geisert, Mathieu and Gangapurwala, Siddhant and Engelcke, Martin and Jones, Oiwi Parker and Havoutis, Ioannis and Posner, Ingmar},
  urldate    = {2025-07-14},
  date       = {2023-07-12},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2205.01179 [cs]},
  keywords   = {Computer Science - Machine Learning, Computer Science - Robotics},
  file       = {2023 - VAE-Loco Versatile Quadruped Locomotion by Learning a Disentangled Gait Representation.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2023 - VAE-Loco Versatile Quadruped Locomotion by Learning a Disentangled Gait Representation.pdf:application/pdf}
}

@misc{zhang_novel_2024,
  title      = {A Novel Multi-Gait Strategy for Stable and Efficient Quadruped Robot Locomotion},
  url        = {http://arxiv.org/abs/2410.09336},
  doi        = {10.48550/arXiv.2410.09336},
  abstract   = {Taking inspiration from the natural gait transition mechanism of quadrupeds, devising a good gait transition strategy is important for quadruped robots to achieve energyefficient locomotion on various terrains and velocities. While previous studies have recognized that gait patterns linked to velocities impact two key factors, the Cost of Transport ({CoT}) and the stability of robot locomotion, only a limited number of studies have effectively combined these factors to design a mechanism that ensures both efficiency and stability in quadruped robot locomotion. In this paper, we propose a multi-gait selection and transition strategy to achieve stable and efficient locomotion across different terrains. Our strategy starts by establishing a gait mapping considering both {CoT} and locomotion stability to guide the gait selection process during locomotion. Then, we achieve gait switching in time by introducing affine transformations for gait parameters and a designed finite state machine to build the switching order. Comprehensive experiments have been conducted on using our strategy with changing terrains and velocities, and the results indicate that our proposed strategy outperforms baseline methods in achieving simultaneous efficiency in locomotion by considering {CoT} and stability.},
  number     = {{arXiv}:2410.09336},
  publisher  = {{arXiv}},
  author     = {Zhang, Daoxun and Chen, Xieyuanli and Zhong, Zhengyu and Xu, Ming and Zheng, Zhiqiang and Lu, Huimin},
  urldate    = {2025-07-14},
  date       = {2024-10-12},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2410.09336 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2024 - A Novel Multi-Gait Strategy for Stable and Efficient Quadruped Robot Locomotion.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2024 - A Novel Multi-Gait Strategy for Stable and Efficient Quadruped Robot Locomotion.pdf:application/pdf}
}

@misc{kaup_review_2024,
  title      = {A Review of Nine Physics Engines for Reinforcement Learning Research},
  url        = {http://arxiv.org/abs/2407.08590},
  doi        = {10.48550/arXiv.2407.08590},
  abstract   = {We present a review of popular simulation engines and frameworks used in reinforcement learning ({RL}) research, aiming to guide researchers in selecting tools for creating simulated physical environments for {RL} and training setups. It evaluates nine frameworks (Brax, Chrono, Gazebo, {MuJoCo}, {ODE}, {PhysX}, {PyBullet}, Webots, and Unity) based on their popularity, feature range, quality, usability, and {RL} capabilities. We highlight the challenges in selecting and utilizing physics engines for {RL} research, including the need for detailed comparisons and an understanding of each framework’s capabilities. Key findings indicate {MuJoCo} as the leading framework due to its performance and flexibility, despite usability challenges. Unity is noted for its ease of use but lacks scalability and simulation fidelity. The study calls for further development to improve simulation engines’ usability and performance and stresses the importance of transparency and reproducibility in {RL} research. This review contributes to the {RL} community by offering insights into the selection process for simulation engines, facilitating informed decision-making.},
  number     = {{arXiv}:2407.08590},
  publisher  = {{arXiv}},
  author     = {Kaup, Michael and Wolff, Cornelius and Hwang, Hyerim and Mayer, Julius and Bruni, Elia},
  urldate    = {2025-07-14},
  date       = {2024-08-23},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2407.08590 [cs]},
  keywords   = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Multiagent Systems},
  file       = {2024 - A Review of Nine Physics Engines for Reinforcement Learning Research.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2024 - A Review of Nine Physics Engines for Reinforcement Learning Research.pdf:application/pdf}
}

@article{bratta_contactnet_2024,
	author = {Bratta, Angelo and Meduri, Avadesh and Focchi, Michele and Righetti, Ludovic and Semini, Claudio},
	title = {{ContactNet: Online Multi-Contact Planning for Acyclic Legged Robot Locomotion}},
	journal = {arXiv},
	year = {2022},
	month = sep,
	eprint = {2209.15566},
	doi = {10.1109/UR61395.2024.10597477}
}

@incollection{gaspard_footstepnet_2024,
	author = {Gaspard, Cl{\ifmmode\acute{e}\else\'{e}\fi}ment and Passault, Gr{\ifmmode\acute{e}\else\'{e}\fi}goire and Daniel, M{\ifmmode\acute{e}\else\'{e}\fi}lodie and Ly, Olivier},
	title = {{FootstepNet: an Efficient Actor-Critic Method for Fast On-line Bipedal Footstep Planning and Forecasting}},
	booktitle = {{2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}},
	journal = {Published in: 2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
	pages = {14--18},
	publisher = {IEEE},
	doi = {10.1109/IROS58592.2024.10802320},
	year = {2024}
}

@article{gao_global_2024,
	author = {Gao, Zhifa and Chen, Xuechao and Yu, Zhangguo and Li, Chao and Han, Lianqiang and Zhang, Runming},
	title = {{Global footstep planning with greedy and heuristic optimization guided by velocity for biped robot}},
	journal = {Expert Syst. Appl.},
	volume = {238},
	pages = {121798},
	year = {2024},
	month = mar,
	issn = {0957-4174},
	publisher = {Pergamon},
	doi = {10.1016/j.eswa.2023.121798}
}

@misc{asselmeier_hierarchical_2024,
  title      = {Hierarchical Experience-informed Navigation for Multi-modal Quadrupedal Rebar Grid Traversal},
  url        = {http://arxiv.org/abs/2311.08354},
  doi        = {10.48550/arXiv.2311.08354},
  abstract   = {This study focuses on a layered, experience-based, multi-modal contact planning framework for agile quadrupedal locomotion over a constrained rebar environment. To this end, our hierarchical planner incorporates locomotion-specific modules into the high-level contact sequence planner and performs kinodynamically-aware trajectory optimization as the low-level motion planner. Through quantitative analysis of the experience accumulation process and experimental validation of the kinodynamic feasibility of the generated locomotion trajectories, we demonstrate that the planning heuristic of experience offers an effective way of providing candidate footholds for a legged contact planner. Additionally, we introduce a guiding torso path heuristic at the global planning level to enhance the navigation success rate in the presence of environmental obstacles. Our results indicate that the torso-path guided experience accumulation requires significantly fewer offline trials to successfully reach the goal compared to regular experience accumulation. Finally, our planning framework is validated in both dynamics simulations and real hardware implementations on a quadrupedal robot provided by Skymul Inc.},
  number     = {{arXiv}:2311.08354},
  publisher  = {{arXiv}},
  author     = {Asselmeier, Max and Ivanova, Jane and Zhou, Ziyi and Vela, Patricio A. and Zhao, Ye},
  urldate    = {2025-07-14},
  date       = {2024-04-13},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2311.08354 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2024 - Hierarchical Experience-informed Navigation for Multi-modal Quadrupedal Rebar Grid Traversal.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2024 - Hierarchical Experience-informed Navigation for Multi-modal Quadrupedal Rebar Grid Traversal.pdf:application/pdf}
}

@article{han_lifelike_2024,
  title        = {Lifelike Agility and Play in Quadrupedal Robots using Reinforcement Learning and Generative Pre-trained Models},
  volume       = {6},
  issn         = {2522-5839},
  url          = {http://arxiv.org/abs/2308.15143},
  doi          = {10.1038/s42256-024-00861-3},
  abstract     = {Knowledge from animals and humans inspires robotic innovations. Numerous efforts have been made to achieve agile locomotion in quadrupedal robots through classical controllers or reinforcement learning approaches. These methods usually rely on physical models or handcrafted rewards to accurately describe the specific system, rather than on a generalized understanding like animals do. Here we propose a hierarchical framework to construct primitive-, environmental- and strategic-level knowledge that are all pre-trainable, reusable and enrichable for legged robots. The primitive module summarizes knowledge from animal motion data, where, inspired by large pre-trained models in language and image understanding, we introduce deep generative models to produce motor control signals stimulating legged robots to act like real animals. Then, we shape various traversing capabilities at a higher level to align with the environment by reusing the primitive module. Finally, a strategic module is trained focusing on complex downstream tasks by reusing the knowledge from previous levels. We apply the trained hierarchical controllers to the {MAX} robot, a quadrupedal robot developed in-house, to mimic animals, traverse complex obstacles and play in a designed challenging multi-agent chase tag game, where lifelike agility and strategy emerge in the robots.},
  pages        = {787--798},
  number       = {7},
  journaltitle = {Nature Machine Intelligence},
  shortjournal = {Nat Mach Intell},
  author       = {Han, Lei and Zhu, Qingxu and Sheng, Jiapeng and Zhang, Chong and Li, Tingguang and Zhang, Yizheng and Zhang, He and Liu, Yuzhen and Zhou, Cheng and Zhao, Rui and Li, Jie and Zhang, Yufeng and Wang, Rui and Chi, Wanchao and Li, Xiong and Zhu, Yonghui and Xiang, Lingzhu and Teng, Xiao and Zhang, Zhengyou},
  urldate      = {2025-07-14},
  date         = {2024-07-05},
  langid       = {english},
  eprinttype   = {arxiv},
  eprint       = {2308.15143 [cs]},
  keywords     = {Computer Science - Artificial Intelligence, Computer Science - Robotics},
  file         = {2024 - Lifelike Agility and Play in Quadrupedal Robots using Reinforcement Learning and Generative Pre-trained Models.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2024 - Lifelike Agility and Play in Quadrupedal Robots using Reinforcement Learning and Generative Pre-trained Models.pdf:application/pdf}
}

@inproceedings{wang_nas_2024,
  location   = {Nancy, France},
  title      = {{NAS}: N-step computation of All Solutions to the footstep planning problem},
  rights     = {https://doi.org/10.15223/policy-029},
  url        = {https://ieeexplore.ieee.org/document/10769878/},
  doi        = {10.1109/humanoids58906.2024.10769878},
  shorttitle = {{NAS}},
  abstract   = {How many ways are there to climb a staircase in a given number of steps? Inﬁnitely many, if we focus on the continuous aspect of the problem. A ﬁnite, possibly large number if we consider the discrete aspect, i.e. on which surface which effectors are going to step and in what order. We introduce {NAS}, an algorithm that considers both aspects simultaneously and computes all the possible solutions to such a contact planning problem, under standard assumptions. To our knowledge {NAS} is the ﬁrst algorithm to produce a globally optimal policy, efﬁciently queried in real time for planning the next footsteps of a humanoid robot.},
  eventtitle = {2024 {IEEE}-{RAS} 23rd International Conference on Humanoid Robots (Humanoids)},
  pages      = {576--583},
  booktitle  = {2024 {IEEE}-{RAS} 23rd International Conference on Humanoid Robots (Humanoids)},
  publisher  = {{IEEE}},
  author     = {Wang, Jiayi and Samadi, Saeid and Wang, Hefan and Fernbach, Pierre and Stasse, Olivier and Vijayakumar, Sethu and Tonneau, Steve},
  urldate    = {2025-07-14},
  date       = {2024-11-22},
  langid     = {english},
  file       = {2024 - NAS N-step computation of All Solutions to the fo.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2024 - NAS N-step computation of All Solutions to the fo.pdf:application/pdf}
}

@article{mittal_orbit_2023,
	author = {Mittal, Mayank and Yu, Calvin and Yu, Qinxi and Liu, Jingzhou and Rudin, Nikita and Hoeller, David and Yuan, Jia Lin and Singh, Ritvik and Guo, Yunrong and Mazhar, Hammad and Mandlekar, Ajay and Babich, Buck and State, Gavriel and Hutter, Marco and Garg, Animesh},
	title = {{Orbit: A Unified Simulation Framework for Interactive Robot Learning Environments}},
	journal = {arXiv},
	year = {2023},
	month = jan,
	eprint = {2301.04195},
	doi = {10.1109/LRA.2023.3270034}
}

@misc{asselmeier_steppability-informed_2024,
  title      = {Steppability-informed Quadrupedal Contact Planning through Deep Visual Search Heuristics},
  url        = {http://arxiv.org/abs/2501.00112},
  doi        = {10.48550/arXiv.2501.00112},
  abstract   = {In this work, we introduce a method for predicting environment steppability – the ability of a legged robot platform to place a foothold at a particular location in the local environment – in the image space. This novel environment representation captures this critical geometric property of the local terrain while allowing us to exploit the computational benefits of sensing and planning in the image space. We adapt a primitive shapes-based synthetic data generation scheme to create geometrically rich and diverse simulation scenes and extract ground truth semantic information in order to train a steppability model. We then integrate this steppability model into an existing interleaved graph search and trajectory optimization-based footstep planner to demonstrate how this steppability paradigm can inform footstep planning in complex, unknown environments. We analyze the steppability model performance to demonstrate its validity, and we deploy the perception-informed footstep planner both in offline and online settings to experimentally verify planning performance.},
  number     = {{arXiv}:2501.00112},
  publisher  = {{arXiv}},
  author     = {Asselmeier, Max and Zhao, Ye and Vela, Patricio A.},
  urldate    = {2025-07-14},
  date       = {2024-12-30},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2501.00112 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2024 - Steppability-informed Quadrupedal Contact Planning.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2024 - Steppability-informed Quadrupedal Contact Planning.pdf:application/pdf}
}

@article{wang_when_2024,
  title        = {When and where to step: Terrain-aware real-time footstep location and timing optimization for bipedal robots},
  volume       = {179},
  rights       = {https://www.elsevier.com/tdm/userlicense/1.0/},
  issn         = {0921-8890},
  url          = {https://linkinghub.elsevier.com/retrieve/pii/S092188902400126X},
  doi          = {10.1016/j.robot.2024.104742},
  shorttitle   = {When and where to step},
  abstract     = {Online footstep planning is essential for bipedal walking robots, allowing them to walk in the presence of disturbances and sensory noise. Most of the literature on the topic has focused on optimizing the footstep placement while keeping the step timing constant. In this work, we introduce a footstep planner capable of optimizing footstep placement and step time online. The proposed planner, consisting of an Interior Point Optimizer ({IPOPT}) and an optimizer based on Augmented Lagrangian ({AL}) method with analytical gradient descent, solves the full dynamics of the Linear Inverted Pendulum ({LIP}) model in real time to optimize for footstep location as well as step timing at the rate of 200 Hz. We show that such asynchronous real-time optimization with the {AL} method ({ARTO}-{AL}) provides the required robustness and speed for successful online footstep planning. Furthermore, {ARTO}-{AL} can be extended to plan footsteps in 3D, allowing terrain-aware footstep planning on uneven terrains. Compared to an algorithm with no footstep time adaptation, our proposed {ARTO}-{AL} demonstrates increased stability in simulated walking experiments as it can resist pushes on flat ground and on a 10◦ ramp up to 120 N and 100 N respectively. Videos2 and open-source code3 are released.},
  pages        = {104742},
  journaltitle = {Robotics and Autonomous Systems},
  author       = {Wang, Ke and Hu, Zhaoyang Jacopo and Tisnikar, Peter and Helander, Oskar and Chappell, Digby and Kormushev, Petar},
  urldate      = {2025-07-14},
  date         = {2024-09},
  langid       = {english},
  note         = {Publisher: Elsevier {BV}},
  file         = {2024 - When and where to step Terrain-aware real-time fo.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2024 - When and where to step Terrain-aware real-time fo.pdf:application/pdf}
}

@misc{schperberg_energy-efficient_2025,
  title      = {Energy-Efficient Motion Planner for Legged Robots},
  url        = {http://arxiv.org/abs/2503.06050},
  doi        = {10.48550/arXiv.2503.06050},
  abstract   = {We propose an online motion planner for legged robot locomotion with the primary objective of achieving energy efficiency. The conceptual idea is to leverage a placement set of footstep positions based on the robot’s body position to determine when and how to execute steps. In particular, the proposed planner uses virtual placement sets beneath the hip joints of the legs and executes a step when the foot is outside of such placement set. Furthermore, we propose a parameter design framework that considers both energy-efficiency and robustness measures to optimize the gait by changing the shape of the placement set along with other parameters, such as step height and swing time, as a function of walking speed. We show that the planner produces trajectories that have a low Cost of Transport ({CoT}) and high robustness measure, and evaluate our approach against model-free Reinforcement Learning ({RL}) and motion imitation using biological dog motion priors as the reference. Overall, within low to medium velocity range, we show a 50.4\% improvement in {CoT} and improved robustness over model-free {RL}, our best performing baseline. Finally, we show ability to handle slippery surfaces, gait transitions, and disturbances in simulation and hardware with the Unitree A1 robot.},
  number     = {{arXiv}:2503.06050},
  publisher  = {{arXiv}},
  author     = {Schperberg, Alexander and Menner, Marcel and Cairano, Stefano Di},
  urldate    = {2025-07-14},
  date       = {2025-06-24},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2503.06050 [cs]},
  keywords   = {Computer Science - Robotics, Computer Science - Systems and Control, Electrical Engineering and Systems Science - Systems and Control},
  file       = {2025 - Energy-Efficient Motion Planner for Legged Robots.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2025 - Energy-Efficient Motion Planner for Legged Robots.pdf:application/pdf}
}

@misc{humphreys_learning_2025,
  title      = {Learning to Adapt through Bio-Inspired Gait Strategies for Versatile Quadruped Locomotion},
  url        = {http://arxiv.org/abs/2412.09440},
  doi        = {10.48550/arXiv.2412.09440},
  abstract   = {Legged robots must adapt their gait to navigate unpredictable environments, a challenge that animals master with ease. However, most deep reinforcement learning ({DRL}) approaches to quadruped locomotion rely on a fixed gait, limiting adaptability to changes in terrain and dynamic state. Here we show that integrating three core principles of animal locomotiongait transition strategies, gait memory and real-time motion adjustments enables a {DRL} control framework to fluidly switch among multiple gaits and recover from instability, all without external sensing. Our framework is guided by biomechanicsinspired metrics that capture efficiency, stability and system limits, which are unified to inform optimal gait selection. The resulting framework achieves blind zero-shot deployment across diverse, real-world terrains and substantially significantly outperforms baseline controllers. By embedding biological principles into data-driven control, this work marks a step towards robust, efficient and versatile robotic locomotion, highlighting how animal motor intelligence can shape the next generation of adaptive machines.},
  number     = {{arXiv}:2412.09440},
  publisher  = {{arXiv}},
  author     = {Humphreys, Joseph and Zhou, Chengxu},
  urldate    = {2025-07-14},
  date       = {2025-06-22},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2412.09440 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2025 - Learning to Adapt through Bio-Inspired Gait Strategies for Versatile Quadruped Locomotion.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2025 - Learning to Adapt through Bio-Inspired Gait Strategies for Versatile Quadruped Locomotion.pdf:application/pdf}
}

@article{ha_learning-based_2025,
  title        = {Learning-based legged locomotion: State of the art and future perspectives},
  volume       = {44},
  rights       = {https://journals.sagepub.com/page/policies/text-and-data-mining-license},
  issn         = {0278-3649, 1741-3176},
  url          = {https://journals.sagepub.com/doi/10.1177/02783649241312698},
  doi          = {10.1177/02783649241312698},
  shorttitle   = {Learning-based legged locomotion},
  abstract     = {Legged locomotion holds the premise of universal mobility, a critical capability for many real-world robotic applications. Both model-based and learning-based approaches have advanced the ﬁeld of legged locomotion in the past three decades. In recent years, however, a number of factors have dramatically accelerated progress in learning-based methods, including the rise of deep learning, rapid progress in simulating robotic systems, and the availability of high-performance and affordable hardware. This article aims to give a brief history of the ﬁeld, to summarize recent efforts in learning locomotion skills for quadrupeds, and to provide researchers new to the area with an understanding of the key issues involved. With the recent proliferation of humanoid robots, we further outline the rapid rise of analogous methods for bipedal locomotion. We conclude with a discussion of open problems as well as related societal impact.},
  pages        = {1396--1427},
  number       = {8},
  journaltitle = {The International Journal of Robotics Research},
  author       = {Ha, Sehoon and Lee, Joonho and Van De Panne, Michiel and Xie, Zhaoming and Yu, Wenhao and Khadiv, Majid},
  urldate      = {2025-07-14},
  date         = {2025-07},
  langid       = {english},
  note         = {Publisher: {SAGE} Publications},
  file         = {2025 - Learning-based legged locomotion State of the art and future perspectives.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2025 - Learning-based legged locomotion State of the art and future perspectives.pdf:application/pdf}
}

@article{taouil_non-gaited_2024,
	author = {Taouil, Ilyass and Amatucci, Lorenzo and Khadiv, Majid and Dai, Angela and Barasuol, Victor and Turrisi, Giulio},
	title = {{Non-Gaited Legged Locomotion With Monte-Carlo Tree Search and Supervised Learning}},
	journal = {IEEE Rob. Autom. Lett.},
	volume = {10},
	number = {2},
	pages = {1265--1272},
	year = {2024},
	month = dec,
	publisher = {IEEE},
	doi = {10.1109/LRA.2024.3519908}
}

@article{wang_walking_2025,
  title        = {Walking control of humanoid robots based on improved footstep planner and whole-body coordination controller},
  volume       = {19},
  rights       = {https://creativecommons.org/licenses/by/4.0/},
  issn         = {1662-5218},
  url          = {https://www.frontiersin.org/articles/10.3389/fnbot.2025.1538979/full},
  doi          = {10.3389/fnbot.2025.1538979},
  abstract     = {High-speed walking is fundamental for humanoid robots to quickly reach the work site in emergency scenarios. According to biological studies, the coordinated motion of the arms and waist can significantly enhance walking speed and stability in humans. However, existing humanoid robot walking control frameworks predominantly focus on leg control, often overlooking the utilization of upper body joints. In this paper, a novel walking control framework combining the improved footstep planner and the whole-body coordination controller is proposed, aiming to improve the humanoid robot's tracking accuracy of desired speeds and its dynamic walking capability. First, we analyze the issues in traditional footstep planners based on Linear Inverted Pendulum and Model Predictive Control ({LIP}-{MPC}). By reconstructing the footstep optimization problem during walking using the Center-of-Mass ({CoM}) position, we propose an improved footstep planner to enhance the control accuracy of the desired walking speed in humanoid robots. Next, based on biological research, we define a coordinated control strategy for the arms and waist during walking. Specifically, the waist increases the robot's step length, while the arms counteract disturbance momentum and maintain balance. Based on the aforementioned strategy, we design a whole-body coordination controller for the humanoid robot. This controller adopts a novel hierarchical design approach, in which the dynamics and motion controllers for the upper and lower body are modeled and managed separately. This helps avoid the issue of poor control performance caused by multi-task coupling in traditional whole-body controllers. Finally, we integrate these controllers into a novel walking control framework and validate it on the simulation prototype of the humanoid robot Dexbot. Simulation results show that the proposed framework significantly enhances the maximum walking capability of the humanoid robot, demonstrating its feasibility and effectiveness.},
  journaltitle = {Frontiers in Neurorobotics},
  shortjournal = {Front. Neurorobot.},
  author       = {Wang, Xiangji and Guo, Wei and Yin, Siyu and Zhang, Sen and Zha, Fusheng and Li, Mantian and Wang, Pengfei and Li, Xiaolin and Sun, Lining},
  urldate      = {2025-07-14},
  date         = {2025-02-21},
  langid       = {english},
  note         = {Publisher: Frontiers Media {SA}},
  file         = {2025 - Walking control of humanoid robots based on improv.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2025 - Walking control of humanoid robots based on improv.pdf:application/pdf}
}

@misc{amatucci_monte_2022,
  title      = {Monte Carlo Tree Search Gait Planner for Non-Gaited Legged System Control},
  url        = {http://arxiv.org/abs/2205.14277},
  doi        = {10.48550/arXiv.2205.14277},
  abstract   = {In this work, a non-gaited framework for legged system locomotion is presented. The approach decouples the gait sequence optimization by considering the problem as a decision-making process. The redeﬁned contact sequence problem is solved by utilizing a Monte Carlo Tree Search ({MCTS}) algorithm that exploits optimization-based simulations to evaluate the best search direction. The proposed scheme has proven to have a good trade-off between exploration and exploitation of the search space compared to the state-ofthe-art Mixed-Integer Quadratic Programming ({MIQP}). The model predictive control ({MPC}) utilizes the gait generated by the {MCTS} to optimize the ground reaction forces and future footholds position. The simulation results, performed on a quadruped robot, showed that the proposed framework could generate known periodic gait and adapt the contact sequence to the encountered conditions, including external forces and terrain with unknown and variable properties. When tested on robots with different layouts, the system has also shown its reliability.},
  number     = {{arXiv}:2205.14277},
  publisher  = {{arXiv}},
  author     = {Amatucci, Lorenzo and Kim, Joon-Ha and Hwangbo, Jemin and Park, Hae-Won},
  urldate    = {2025-07-15},
  date       = {2022-05-28},
  langid     = {english},
  eprinttype = {arxiv},
  eprint     = {2205.14277 [cs]},
  keywords   = {Computer Science - Robotics},
  file       = {2022 - Monte Carlo Tree Search Gait Planner for Non-Gaited Legged System Control.pdf:C\:\\Users\\Owen\\OneDrive - Worcester Polytechnic Institute (wpi.edu)\\2025\\Thesis\\papers\\2022 - Monte Carlo Tree Search Gait Planner for Non-Gaited Legged System Control.pdf:application/pdf}
}

@article{mittal2023orbit,
  author  = {Mittal, Mayank and Yu, Calvin and Yu, Qinxi and Liu, Jingzhou and Rudin, Nikita and Hoeller, David and Yuan, Jia Lin and Singh, Ritvik and Guo, Yunrong and Mazhar, Hammad and Mandlekar, Ajay and Babich, Buck and State, Gavriel and Hutter, Marco and Garg, Animesh},
  journal = {IEEE Robotics and Automation Letters},
  title   = {Orbit: A Unified Simulation Framework for Interactive Robot Learning Environments},
  year    = {2023},
  volume  = {8},
  number  = {6},
  pages   = {3740-3747},
  doi     = {10.1109/LRA.2023.3270034}
}

@article{feng2021deep,
  author   = {Feng, Di and Haase-Schütz, Christian and Rosenbaum, Lars and Hertlein, Heinz and Gläser, Claudius and Timm, Fabian and Wiesbeck, Werner and Dietmayer, Klaus},
  journal  = {IEEE Transactions on Intelligent Transportation Systems},
  title    = {Deep Multi-Modal Object Detection and Semantic Segmentation for Autonomous Driving: Datasets, Methods, and Challenges},
  year     = {2021},
  volume   = {22},
  number   = {3},
  pages    = {1341-1360},
  keywords = {Autonomous vehicles;Object detection;Cameras;Sensors;Laser radar;Fuses;Multi-modality;object detection;semantic segmentation;deep learning;autonomous driving},
  doi      = {10.1109/TITS.2020.2972974}
}
@article{Chai2022survey,
	author = {Chai, Hui and Li, Yibin and Song, Rui and Zhang, Guoteng and Zhang, Qin and Liu, Song and Hou, Jinmian and Xin, Yaxian and Yuan, Ming and Zhang, Guoxuan and Yang, Zhiyuan},
	title = {{A survey of the development of quadruped robots: Joint configuration, dynamic locomotion control method and mobile manipulation approach}},
	journal = {Biomimetic Intelligence and Robotics},
	volume = {2},
	number = {1},
	pages = {100029},
	year = {2022},
	month = mar,
	issn = {2667-3797},
	publisher = {Elsevier},
	doi = {10.1016/j.birob.2021.100029}
}
@article{Fan2024survey,
	author = {Fan, Yanan and Pei, Zhongcai and Wang, Chen and Li, Meng and Tang, Zhiyong and Liu, Qinghua},
	title = {{A Review of Quadruped Robots: Structure, Control, and Autonomous Motion}},
	journal = {Adv. Intell. Syst.},
	volume = {6},
	number = {6},
	pages = {2300783},
	year = {2024},
	month = jun,
	issn = {2640-4567},
	publisher = {John Wiley {\&} Sons, Ltd},
	doi = {10.1002/aisy.202300783}
}
@article{Kim2019highly-dynamic,
	author = {Kim, Donghyun and Di Carlo, Jared and Katz, Benjamin and Bledt, Gerardo and Kim, Sangbae},
	title = {{Highly Dynamic Quadruped Locomotion via Whole-Body Impulse Control and Model Predictive Control}},
	journal = {arXiv},
	year = {2019},
	month = sep,
	eprint = {1909.06586},
	doi = {10.48550/arXiv.1909.06586}
}
@article{Geisert2019contact-planning,
	author = {Geisert, Mathieu and Yates, Thomas and Orgen, Asil and Fernbach, Pierre and Havoutis, Ioannis},
	title = {{Contact Planning for the ANYmal Quadruped Robot using an Acyclic Reachability-Based Planner}},
	journal = {arXiv},
	year = {2019},
	month = apr,
	eprint = {1904.08238},
	doi = {10.48550/arXiv.1904.08238}
}
@article{Gurram2024survey,
	author = {Gurram, Maurya and Uttam, Prakash Kumar and Ohol, Shantipal S.},
	title = {{Reinforcement Learning For Quadrupedal Locomotion: Current Advancements And Future Perspectives}},
	journal = {arXiv},
	year = {2024},
	month = oct,
	eprint = {2410.10438},
	doi = {10.48550/arXiv.2410.10438}
}
@article{Bao2024survey,
	author = {Bao, Lingfan and Humphreys, Joseph and Peng, Tianhu and Zhou, Chengxu},
	title = {{Deep Reinforcement Learning for Bipedal Locomotion: A Brief Survey}},
	journal = {arXiv},
	year = {2024},
	month = apr,
	eprint = {2404.17070},
	doi = {10.48550/arXiv.2404.17070}
}
@article{Wang2022Oct,
	author = {Wang, Zhicheng and Wei, Wandi and Xie, Anhuan and Zhang, Yifeng and Wu, Jun and Zhu, Qiuguo},
	title = {{Hybrid Bipedal Locomotion Based on Reinforcement Learning and Heuristics}},
	journal = {Micromachines},
	volume = {13},
	number = {10},
	pages = {1688},
	year = {2022},
	month = oct,
	issn = {2072-666X},
	publisher = {Multidisciplinary Digital Publishing Institute},
	doi = {10.3390/mi13101688}
}
@article{Meng2023Mar,
	author = {Meng, Yue and Fan, Chuchu},
	title = {{Hybrid Systems Neural Control with Region-of-Attraction Planner}},
	journal = {arXiv},
	year = {2023},
	month = mar,
	eprint = {2303.10327},
	doi = {10.48550/arXiv.2303.10327}
}
@article{Wensing2022Nov,
	author = {Wensing, Patrick M. and Posa, Michael and Hu, Yue and Escande, Adrien and Mansard, Nicolas and Del Prete, Andrea},
	title = {{Optimization-Based Control for Dynamic Legged Robots}},
	journal = {arXiv},
	year = {2022},
	month = nov,
	eprint = {2211.11644},
	doi = {10.48550/arXiv.2211.11644}
}
@article{Makoviychuk_isaac_2021,
	author = {Makoviychuk, Viktor and Wawrzyniak, Lukasz and Guo, Yunrong and Lu, Michelle and Storey, Kier and Macklin, Miles and Hoeller, David and Rudin, Nikita and Allshire, Arthur and Handa, Ankur and State, Gavriel},
	title = {{Isaac Gym: High Performance GPU-Based Physics Simulation For Robot Learning}},
	journal = {arXiv},
	year = {2021},
	month = aug,
	eprint = {2108.10470},
	doi = {10.48550/arXiv.2108.10470}
}
@article{Schulman_proximal_2017,
	author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	title = {{Proximal Policy Optimization Algorithms}},
	journal = {arXiv},
	year = {2017},
	month = jul,
	eprint = {1707.06347},
	doi = {10.48550/arXiv.1707.06347}
}
@article{bishop_relu_2023,
	author = {Bishop, Arun L. and Zhang, John Z. and Gurumurthy, Swaminathan and Tracy, Kevin and Manchester, Zachary},
	title = {{ReLU-QP: A GPU-Accelerated Quadratic Programming Solver for Model-Predictive Control}},
	journal = {arXiv},
	year = {2023},
	month = nov,
	eprint = {2311.18056},
	doi = {10.48550/arXiv.2311.18056}
}
@phdthesis{Plancher22Dissertation,
  title={GPU Acceleration for Real-time, Whole-body, Nonlinear Model Predictive Control},
  author={Plancher, Brian},
  school={Harvard University},
  year={2022},
  address = {Cambridge, MA, USA},
  month={April}
}
@article{sun_online_2024,
	author = {Sun, Hao and Yang, Junjie and Jia, Yinghao and Wang, Changhong},
	title = {{Online Hierarchical Planning for Multicontact Locomotion Control of Quadruped Robots}},
	journal = {IEEE/ASME Trans. Mechatron.},
	volume = {30},
	number = {3},
	pages = {1718--1728},
	year = {2024},
	month = jul,
	publisher = {IEEE},
	doi = {10.1109/TMECH.2024.3412920}
}
@article{olkin_locomotion_2025,
	author = {Olkin, Zachary and Ames, Aaron D.},
	title = {{Locomotion on Constrained Footholds via Layered Architectures and Model Predictive Control}},
	journal = {arXiv},
	year = {2025},
	month = jun,
	eprint = {2506.09979},
	doi = {10.48550/arXiv.2506.09979}
}
@article{ha_learning_2024,
	author = {Ha, Sehoon and Lee, Joonho and van de Panne, Michiel and Xie, Zhaoming and Yu, Wenhao and Khadiv, Majid},
	title = {{Learning-based legged locomotion; state of the art and future perspectives}},
	journal = {arXiv},
	year = {2024},
	month = jun,
	eprint = {2406.01152},
	doi = {10.48550/arXiv.2406.01152}
}
@article{tolomei_learning_2025,
	author = {Tolomei, Simone and Belter, Dominik and Bednarek, Jakub and Angelini, Franco and Garabini, Manolo},
	title = {{Learning-Based Foot-Shape-Aware Foothold Selection for Quadrupedal Robots}},
	journal = {IEEE Transactions on Systems, Man, and Cybernetics: Systems},
	volume = {55},
	number = {8},
	pages = {5234--5247},
	year = {2025},
	month = may,
	publisher = {IEEE},
	doi = {10.1109/TSMC.2025.3563974}
}
@article{akizhanov_learning_2024,
	author = {Akizhanov, Rikhat and Dh{\ifmmode\acute{e}\else\'{e}\fi}din, Victor and Khadiv, Majid and Laptev, Ivan},
	title = {{Learning feasible transitions for efficient contact planning}},
	journal = {arXiv},
	year = {2024},
	month = jul,
	eprint = {2407.11788},
	doi = {10.48550/arXiv.2407.11788}
}
@article{zhang_learning_2023,
	author = {Zhang, Chong and Rudin, Nikita and Hoeller, David and Hutter, Marco},
	title = {{Learning Agile Locomotion on Risky Terrains}},
	journal = {arXiv},
	year = {2023},
	month = nov,
	eprint = {2311.10484},
	doi = {10.48550/arXiv.2311.10484}
}
@article{chen_gait_2024,
	author = {Chen, Liuhongxu and Du, Ping and Zhan, Pengfei and Xie, Bo},
	title = {{Gait Learning for Hexapod Robot Facing Rough Terrain Based on Dueling-DQN Algorithm}},
	journal = {International Journal of Computer Science and Information Technology},
	volume = {2},
	number = {1},
	pages = {408--424},
	year = {2024},
	month = mar,
	issn = {3005-9682},
	publisher = {Warwick Evans Publishing},
	doi = {10.62051/ijcsit.v2n1.44}
}
@incollection{yao_hierarchical_2021,
	author = {Yao, Qingfeng and Wang, Jilong and Wang, Donglin and Yang, Shuyu and Zhang, Hongyin and Wang, Yinuo},
	title = {{Hierarchical Terrain-Aware Control for Quadrupedal Locomotion by Combining Deep Reinforcement Learning and Optimal Control}},
	booktitle = {{2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}},
	journal = {Published in: 2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
	pages = {2021--01},
	publisher = {IEEE},
	doi = {10.1109/IROS51168.2021.9636738}
}
@article{yang_fast_2021,
	author = {Yang, Yuxiang and Zhang, Tingnan and Coumans, Erwin and Tan, Jie and Boots, Byron},
	title = {{Fast and Efficient Locomotion via Learned Gait Transitions}},
	journal = {arXiv},
	year = {2021},
	month = apr,
	eprint = {2104.04644},
	doi = {10.48550/arXiv.2104.04644}
}
@incollection{meduri_deepq_2021,
	author = {Meduri, Avadesh and Khadiv, Majid and Righetti, Ludovic},
	title = {{DeepQ Stepper: A framework for reactive dynamic walking on uneven terrain}},
	booktitle = {{2021 IEEE International Conference on Robotics and Automation (ICRA)}},
	journal = {Published in: 2021 IEEE International Conference on Robotics and Automation (ICRA)},
	pages = {2021--05},
	publisher = {IEEE},
	doi = {10.1109/ICRA48506.2021.9562093}
}
@article{da_learning_2020,
	author = {Da, Xingye and Xie, Zhaoming and Hoeller, David and Boots, Byron and Anandkumar, Animashree and Zhu, Yuke and Babich, Buck and Garg, Animesh},
	title = {{Learning a Contact-Adaptive Controller for Robust, Efficient Legged Locomotion}},
	journal = {arXiv},
	year = {2020},
	month = sep,
	eprint = {2009.10019},
	doi = {10.48550/arXiv.2009.10019}
}
@article{aceituno_simultaneous_2019,
	author = {Aceituno-Cabezas, Bernardo and Mastalli, Carlos and Dai, Hongkai and Focchi, Michele and Radulescu, Andreea and Caldwell, Darwin G. and Cappelletto, Jose and Grieco, Juan C. and Fernandez-Lopez, Gerardo and Semini, Claudio},
	title = {{Simultaneous Contact, Gait and Motion Planning for Robust Multi-Legged Locomotion via Mixed-Integer Convex Optimization}},
	journal = {arXiv},
	year = {2019},
	month = apr,
	eprint = {1904.04595},
	doi = {10.1109/LRA.2017.2779821}
}
@incollection{deits_footstep_2014,
	author = {Deits, Robin and Tedrake, Russ},
	title = {{Footstep planning on uneven terrain with mixed-integer convex optimization}},
	booktitle = {{2014 IEEE-RAS International Conference on Humanoid Robots}},
	pages = {18--20},
  year = {2014},
	isbn = {978-1-4799-7174-9},
	publisher = {IEEE},
	doi = {10.1109/HUMANOIDS.2014.7041373}
}

@phdthesis{di_mini_cheetah_2020,
	author = {Di Carlo, Jared(Jared J. )},
	title = {{Software and control design for the MIT Cheetah quadruped robots}},
	year = {2020},
	school = {Massachusetts Institute of Technology},
	url = {https://dspace.mit.edu/handle/1721.1/129877}
}

@misc{zhuang_rl_mpc_locomotion_2025,
  author = {Yulun Zhuang},
	title = {{rl-mpc-locomotion}},
	journal = {GitHub},
	year = {2025},
	month = nov,
	note = {[Online; accessed 17. Nov. 2025]},
	url = {https://github.com/silvery107/rl-mpc-locomotion}
}

@article{gangapurwala_rloc_2022,
	author = {Gangapurwala, Siddhant and Geisert, Mathieu and Orsolino, Romeo and Fallon, Maurice and Havoutis, Ioannis},
	title = {{RLOC: Terrain-Aware Legged Locomotion Using Reinforcement Learning and Optimal Control}},
	journal = {IEEE Trans. Rob.},
	volume = {38},
	number = {5},
	pages = {2908--2927},
	year = {2022},
	month = may,
	publisher = {IEEE},
	doi = {10.1109/TRO.2022.3172469}
}